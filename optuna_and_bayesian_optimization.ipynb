{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optuna_and_bayesian optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaWQgCzdi36C1601SR8goI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/classification/blob/main/optuna_and_bayesian_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcQ9K-OqwRD5"
      },
      "source": [
        "# Last amended: 8th July, 2021\n",
        "# Myfolder: C:\\Users\\Administrator\\OneDrive\\Documents\\breast_cancer\n",
        "#\n",
        "# Ref: https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258\n",
        "#      https://github.com/optuna/optuna/blob/master/examples/lightgbm_tuner_simple.py\n",
        "#\n",
        "# Objective:\n",
        "#           i) Learn to use automated tuning of lightgbm\n",
        "#          ii) Using optuna\n",
        "#         iii) Perform Bayesian optimization\n",
        "#          iv) Optimizing Pipeline\n",
        "#\n",
        "# See also 'h2o_talkingData.ipynb' in folder:\n",
        "#   C:\\Users\\Administrator\\OneDrive\\Documents\\talkingdata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PTJLI1TwXpM"
      },
      "source": [
        "\"\"\"\n",
        "Optuna example that optimizes a classifier configuration\n",
        "using LightGBM tuner.\n",
        "In this example, we optimize the validation log loss\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7stik-g6oJM"
      },
      "source": [
        "### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nrZkaz-yXdA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "fda8410d-117c-4a6c-a000-01fddd351955"
      },
      "source": [
        "# 0.0 Downgrade sklearn\n",
        "#     Higher version gives problem with BayesSearchCV (skopt)\n",
        "#     conda install -c intel scikit-learn==0.23.2\n",
        "\n",
        "! pip install scikit-learn==0.23.2 \n",
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (0.23.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (2.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2) (1.4.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.23.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbcFRRTTwZPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422f6c70-4972-4a19-e43f-bb7bb04f46d1"
      },
      "source": [
        "# 0.1 Optuna\n",
        "#     https://optuna.org/\n",
        "! pip install optuna"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.6.5)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.18)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (5.0.1)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: python-editor>=0.3 in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.0.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.1.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.13)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.6.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna) (3.4.1)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: colorama>=0.3.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.4.4)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzZNaCAP1q4X"
      },
      "source": [
        "# 0.2 sklearn optimizer\n",
        "# \n",
        "!pip install scikit-optimize\n",
        "!pip install 'scikit-optimize[plots]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUrdExgY1uck"
      },
      "source": [
        "# 0.3 Lightgbm\n",
        "! pip install lightgbm --upgrade\n",
        "import lightgbm\n",
        "lightgbm.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsDq4tH_WrnW"
      },
      "source": [
        "### Call libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l29Rt56cwd-q"
      },
      "source": [
        "# 1.0 Call libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1.1 Import optuna integration with lightgbm\n",
        "# Install as: conda install -c conda-forge optuna\n",
        "import optuna.integration.lightgbm as lgbm\n",
        "\n",
        "\n",
        "# 1.2  Return stratified folds. The folds are made by\n",
        "#      preserving the percentage of samples for each class.\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import auc, roc_curve\n",
        "\n",
        "# 1.3 ML - we will classify using lightgbm\n",
        "#          with stratified cross validation\n",
        "#          conda install -c conda-forge lightgbm \n",
        "import lightgbm as lgb\n",
        "\n",
        "# 1.4 OS related\n",
        "import os, time\n",
        "\n",
        "# 1.5 Bayes optimization--IInd method\n",
        "# SKOPT is a parameter-optimisation framewor\n",
        "#  Install skopt as:\n",
        "#     conda install -c conda-forge scikit-optimize\n",
        "\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "# 1.6\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU53Wl2S0rHx"
      },
      "source": [
        "# 1.7\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN0lcnrLWwy9"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfd3gJ7tx5Wp"
      },
      "source": [
        "# # 2.0 Get data and split it\n",
        "data,target = make_classification(  n_samples = 10000,\n",
        "                                    n_features = 25,\n",
        "                                    n_informative = 20,\n",
        "                                    n_redundant = 2,\n",
        "                                    n_repeated = 3,\n",
        "                                    n_classes = 2,\n",
        "                                    flip_y = 0.01,\n",
        "                                    shuffle = True\n",
        "                                  )"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD4takEIXj_F"
      },
      "source": [
        "#### Create some categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6NqVd2DXo2c",
        "outputId": "e6210cda-7008-4abd-98c5-a7c405b4e876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# 2.1 Transform to pandas dataframe\n",
        "df = pd.DataFrame(data, columns = [\"c\" + str(i) for i in range(25)])\n",
        "df.head(2)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c0</th>\n",
              "      <th>c1</th>\n",
              "      <th>c2</th>\n",
              "      <th>c3</th>\n",
              "      <th>c4</th>\n",
              "      <th>c5</th>\n",
              "      <th>c6</th>\n",
              "      <th>c7</th>\n",
              "      <th>c8</th>\n",
              "      <th>c9</th>\n",
              "      <th>c10</th>\n",
              "      <th>c11</th>\n",
              "      <th>c12</th>\n",
              "      <th>c13</th>\n",
              "      <th>c14</th>\n",
              "      <th>c15</th>\n",
              "      <th>c16</th>\n",
              "      <th>c17</th>\n",
              "      <th>c18</th>\n",
              "      <th>c19</th>\n",
              "      <th>c20</th>\n",
              "      <th>c21</th>\n",
              "      <th>c22</th>\n",
              "      <th>c23</th>\n",
              "      <th>c24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.374429</td>\n",
              "      <td>-3.801091</td>\n",
              "      <td>-0.792911</td>\n",
              "      <td>2.253009</td>\n",
              "      <td>-1.052819</td>\n",
              "      <td>-1.917159</td>\n",
              "      <td>1.327901</td>\n",
              "      <td>2.253009</td>\n",
              "      <td>-2.047104</td>\n",
              "      <td>1.803323</td>\n",
              "      <td>-2.395860</td>\n",
              "      <td>0.600562</td>\n",
              "      <td>-2.253816</td>\n",
              "      <td>-1.560202</td>\n",
              "      <td>0.351420</td>\n",
              "      <td>-0.765896</td>\n",
              "      <td>1.117091</td>\n",
              "      <td>-2.594506</td>\n",
              "      <td>-2.931400</td>\n",
              "      <td>-4.486719</td>\n",
              "      <td>-2.668279</td>\n",
              "      <td>-3.082582</td>\n",
              "      <td>1.327901</td>\n",
              "      <td>0.821409</td>\n",
              "      <td>-0.792911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.764841</td>\n",
              "      <td>1.651728</td>\n",
              "      <td>9.845462</td>\n",
              "      <td>0.658744</td>\n",
              "      <td>3.945355</td>\n",
              "      <td>-0.226803</td>\n",
              "      <td>2.590126</td>\n",
              "      <td>0.658744</td>\n",
              "      <td>0.839470</td>\n",
              "      <td>-4.099876</td>\n",
              "      <td>-0.524466</td>\n",
              "      <td>-4.554815</td>\n",
              "      <td>1.412110</td>\n",
              "      <td>-2.944011</td>\n",
              "      <td>-2.113245</td>\n",
              "      <td>-3.489946</td>\n",
              "      <td>4.068615</td>\n",
              "      <td>1.210525</td>\n",
              "      <td>-0.750784</td>\n",
              "      <td>-2.363587</td>\n",
              "      <td>-3.876824</td>\n",
              "      <td>-0.648575</td>\n",
              "      <td>2.590126</td>\n",
              "      <td>2.527653</td>\n",
              "      <td>9.845462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         c0        c1        c2  ...       c22       c23       c24\n",
              "0  0.374429 -3.801091 -0.792911  ...  1.327901  0.821409 -0.792911\n",
              "1  0.764841  1.651728  9.845462  ...  2.590126  2.527653  9.845462\n",
              "\n",
              "[2 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHC_itFeYEyU",
        "outputId": "e575db2c-969d-40b0-b921-49fec79226ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# 2.2 To discrete\n",
        "\n",
        "df[\"c0\"] = pd.cut(df[\"c0\"], 3, labels = [\"l\", \"m\", \"h\"])\n",
        "df[\"c1\"] = pd.qcut(df[\"c1\"], [0.0,0.25,0.50,0.75,1], labels = [\"l\", \"m\", \"h\", \"vh\"])\n",
        "df.head(2)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c0</th>\n",
              "      <th>c1</th>\n",
              "      <th>c2</th>\n",
              "      <th>c3</th>\n",
              "      <th>c4</th>\n",
              "      <th>c5</th>\n",
              "      <th>c6</th>\n",
              "      <th>c7</th>\n",
              "      <th>c8</th>\n",
              "      <th>c9</th>\n",
              "      <th>c10</th>\n",
              "      <th>c11</th>\n",
              "      <th>c12</th>\n",
              "      <th>c13</th>\n",
              "      <th>c14</th>\n",
              "      <th>c15</th>\n",
              "      <th>c16</th>\n",
              "      <th>c17</th>\n",
              "      <th>c18</th>\n",
              "      <th>c19</th>\n",
              "      <th>c20</th>\n",
              "      <th>c21</th>\n",
              "      <th>c22</th>\n",
              "      <th>c23</th>\n",
              "      <th>c24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>m</td>\n",
              "      <td>l</td>\n",
              "      <td>-0.792911</td>\n",
              "      <td>2.253009</td>\n",
              "      <td>-1.052819</td>\n",
              "      <td>-1.917159</td>\n",
              "      <td>1.327901</td>\n",
              "      <td>2.253009</td>\n",
              "      <td>-2.047104</td>\n",
              "      <td>1.803323</td>\n",
              "      <td>-2.395860</td>\n",
              "      <td>0.600562</td>\n",
              "      <td>-2.253816</td>\n",
              "      <td>-1.560202</td>\n",
              "      <td>0.351420</td>\n",
              "      <td>-0.765896</td>\n",
              "      <td>1.117091</td>\n",
              "      <td>-2.594506</td>\n",
              "      <td>-2.931400</td>\n",
              "      <td>-4.486719</td>\n",
              "      <td>-2.668279</td>\n",
              "      <td>-3.082582</td>\n",
              "      <td>1.327901</td>\n",
              "      <td>0.821409</td>\n",
              "      <td>-0.792911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>m</td>\n",
              "      <td>vh</td>\n",
              "      <td>9.845462</td>\n",
              "      <td>0.658744</td>\n",
              "      <td>3.945355</td>\n",
              "      <td>-0.226803</td>\n",
              "      <td>2.590126</td>\n",
              "      <td>0.658744</td>\n",
              "      <td>0.839470</td>\n",
              "      <td>-4.099876</td>\n",
              "      <td>-0.524466</td>\n",
              "      <td>-4.554815</td>\n",
              "      <td>1.412110</td>\n",
              "      <td>-2.944011</td>\n",
              "      <td>-2.113245</td>\n",
              "      <td>-3.489946</td>\n",
              "      <td>4.068615</td>\n",
              "      <td>1.210525</td>\n",
              "      <td>-0.750784</td>\n",
              "      <td>-2.363587</td>\n",
              "      <td>-3.876824</td>\n",
              "      <td>-0.648575</td>\n",
              "      <td>2.590126</td>\n",
              "      <td>2.527653</td>\n",
              "      <td>9.845462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  c0  c1        c2        c3  ...       c21       c22       c23       c24\n",
              "0  m   l -0.792911  2.253009  ... -3.082582  1.327901  0.821409 -0.792911\n",
              "1  m  vh  9.845462  0.658744  ... -0.648575  2.590126  2.527653  9.845462\n",
              "\n",
              "[2 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ljsg2Qmaa-m0"
      },
      "source": [
        "#### Transform cat features to integers\n",
        "Using map() or LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLDVRDs1cKSU",
        "outputId": "30518a57-00bb-4426-a4e7-faac0b5a7d43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "# 2.3\n",
        "df[\"c0\"] = df[\"c0\"].map({\"l\" : \"0\", \"m\" : \"1\", \"h\" : \"2\"})\n",
        "df[\"c1\"] = df[\"c1\"].map({\"l\" : \"0\", \"m\" : \"1\", \"h\" : \"2\", \"vh\" : \"3\"})\n",
        "df.head(2)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c0</th>\n",
              "      <th>c1</th>\n",
              "      <th>c2</th>\n",
              "      <th>c3</th>\n",
              "      <th>c4</th>\n",
              "      <th>c5</th>\n",
              "      <th>c6</th>\n",
              "      <th>c7</th>\n",
              "      <th>c8</th>\n",
              "      <th>c9</th>\n",
              "      <th>c10</th>\n",
              "      <th>c11</th>\n",
              "      <th>c12</th>\n",
              "      <th>c13</th>\n",
              "      <th>c14</th>\n",
              "      <th>c15</th>\n",
              "      <th>c16</th>\n",
              "      <th>c17</th>\n",
              "      <th>c18</th>\n",
              "      <th>c19</th>\n",
              "      <th>c20</th>\n",
              "      <th>c21</th>\n",
              "      <th>c22</th>\n",
              "      <th>c23</th>\n",
              "      <th>c24</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.792911</td>\n",
              "      <td>2.253009</td>\n",
              "      <td>-1.052819</td>\n",
              "      <td>-1.917159</td>\n",
              "      <td>1.327901</td>\n",
              "      <td>2.253009</td>\n",
              "      <td>-2.047104</td>\n",
              "      <td>1.803323</td>\n",
              "      <td>-2.395860</td>\n",
              "      <td>0.600562</td>\n",
              "      <td>-2.253816</td>\n",
              "      <td>-1.560202</td>\n",
              "      <td>0.351420</td>\n",
              "      <td>-0.765896</td>\n",
              "      <td>1.117091</td>\n",
              "      <td>-2.594506</td>\n",
              "      <td>-2.931400</td>\n",
              "      <td>-4.486719</td>\n",
              "      <td>-2.668279</td>\n",
              "      <td>-3.082582</td>\n",
              "      <td>1.327901</td>\n",
              "      <td>0.821409</td>\n",
              "      <td>-0.792911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>9.845462</td>\n",
              "      <td>0.658744</td>\n",
              "      <td>3.945355</td>\n",
              "      <td>-0.226803</td>\n",
              "      <td>2.590126</td>\n",
              "      <td>0.658744</td>\n",
              "      <td>0.839470</td>\n",
              "      <td>-4.099876</td>\n",
              "      <td>-0.524466</td>\n",
              "      <td>-4.554815</td>\n",
              "      <td>1.412110</td>\n",
              "      <td>-2.944011</td>\n",
              "      <td>-2.113245</td>\n",
              "      <td>-3.489946</td>\n",
              "      <td>4.068615</td>\n",
              "      <td>1.210525</td>\n",
              "      <td>-0.750784</td>\n",
              "      <td>-2.363587</td>\n",
              "      <td>-3.876824</td>\n",
              "      <td>-0.648575</td>\n",
              "      <td>2.590126</td>\n",
              "      <td>2.527653</td>\n",
              "      <td>9.845462</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  c0 c1        c2        c3  ...       c21       c22       c23       c24\n",
              "0  1  0 -0.792911  2.253009  ... -3.082582  1.327901  0.821409 -0.792911\n",
              "1  1  3  9.845462  0.658744  ... -0.648575  2.590126  2.527653  9.845462\n",
              "\n",
              "[2 rows x 25 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_Ui_6iUXsKN",
        "outputId": "8d81d391-20e1-46c4-ccd5-62d8144841f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 2.4\n",
        "train_x, val_x, train_y, val_y = train_test_split(\n",
        "                                                  data,\n",
        "                                                  target,\n",
        "                                                  test_size=0.25,\n",
        "                                                  shuffle=True,\n",
        "                                                  stratify = target\n",
        "                                                  )\n",
        "\n",
        "train_x.shape  # 7500, 25)\n",
        "val_x.shape    # (2500, 25)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7500, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XKHTldcXAVG"
      },
      "source": [
        "## Optuna lightgbm modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6CJ-Q_MW1QF"
      },
      "source": [
        "#### Transform data to lgbm data format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOasDve-zYji"
      },
      "source": [
        "# 2.1 Transform train_x and val_x to lightgbm data-matricies\n",
        "# Ref: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.Dataset.html\n",
        "\n",
        "dtrain = lgbm.Dataset(train_x,\n",
        "                      label=train_y,\n",
        "                      categorical_feature = [0,1]\n",
        "                      )\n",
        "\n",
        "dval = lgbm.Dataset(\n",
        "                     val_x,\n",
        "                     label=val_y,\n",
        "                     categorical_feature = [0,1]\n",
        "                    )"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg1fnC9DXHv1"
      },
      "source": [
        "### Declare fixed parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcUeQ5ZyznNZ"
      },
      "source": [
        "# 3.0 Set fixed hyper-params\n",
        "params_fixed = {                           # Specify params that are fixed\n",
        "                 \"objective\": \"binary\",\n",
        "                 \"metric\": \"binary_logloss\",\n",
        "                 \"verbosity\": -1,\n",
        "                 \"boosting_type\": \"gbdt\",\n",
        "                }"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFFoup8-XLaO"
      },
      "source": [
        "### Build model for tuning\n",
        "Tune hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sTFJFQtzuHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7adb68-1576-4ad3-a409-45508a3399ed"
      },
      "source": [
        "# 3.1 Note that unlike in sklearn, here there is\n",
        "#     no instantiation of LightGBM model\n",
        "#     Start modeling as also tuning hyperparameters\n",
        "\n",
        "model = lgbm.train(\n",
        "                   params_fixed,               # Just fixed params only\n",
        "                   dtrain,                     # Dataset\n",
        "                   valid_sets=[dtrain, dval],  # Evaluate performance on these datasets\n",
        "                   verbose_eval=100,\n",
        "                   early_stopping_rounds=100,\n",
        "                   categorical_feature = [0,1] # columns 0 and 1 are categorical\n",
        "                  )\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-08 14:38:12,428]\u001b[0m A new study created in memory with name: no-name-ef097d50-4749-4397-9166-12d798c3685f\u001b[0m\n",
            "\n",
            "\n",
            "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:1433: UserWarning:\n",
            "\n",
            "Overriding the parameters from Reference Dataset.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py:1245: UserWarning:\n",
            "\n",
            "categorical_column in param dict is overridden.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0734411\tvalid_1's binary_logloss: 0.169354\n",
            "[200]\tvalid_0's binary_logloss: 0.0219475\tvalid_1's binary_logloss: 0.135854\n",
            "[300]\tvalid_0's binary_logloss: 0.00641305\tvalid_1's binary_logloss: 0.127846\n",
            "[400]\tvalid_0's binary_logloss: 0.0019557\tvalid_1's binary_logloss: 0.12864\n",
            "Early stopping, best iteration is:\n",
            "[343]\tvalid_0's binary_logloss: 0.00382634\tvalid_1's binary_logloss: 0.126784\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:   0%|          | 0/7 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  14%|#4        | 1/7 [00:02<00:13,  2.24s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:14,691]\u001b[0m Trial 0 finished with value: 0.1267842635946944 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.1267842635946944.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  14%|#4        | 1/7 [00:02<00:13,  2.24s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0815043\tvalid_1's binary_logloss: 0.174535\n",
            "[200]\tvalid_0's binary_logloss: 0.0247984\tvalid_1's binary_logloss: 0.1373\n",
            "[300]\tvalid_0's binary_logloss: 0.0076537\tvalid_1's binary_logloss: 0.1277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  14%|#4        | 1/7 [00:04<00:13,  2.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[400]\tvalid_0's binary_logloss: 0.00244222\tvalid_1's binary_logloss: 0.129646\n",
            "Early stopping, best iteration is:\n",
            "[332]\tvalid_0's binary_logloss: 0.00520264\tvalid_1's binary_logloss: 0.126903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  29%|##8       | 2/7 [00:04<00:10,  2.15s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:16,630]\u001b[0m Trial 1 finished with value: 0.12690329256169067 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.1267842635946944.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  29%|##8       | 2/7 [00:04<00:10,  2.15s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0753099\tvalid_1's binary_logloss: 0.170099\n",
            "[200]\tvalid_0's binary_logloss: 0.0224402\tvalid_1's binary_logloss: 0.135378\n",
            "[300]\tvalid_0's binary_logloss: 0.00687582\tvalid_1's binary_logloss: 0.130473\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  29%|##8       | 2/7 [00:06<00:10,  2.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  43%|####2     | 3/7 [00:06<00:08,  2.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:18,459]\u001b[0m Trial 2 finished with value: 0.1296152922430984 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.1267842635946944.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  43%|####2     | 3/7 [00:06<00:08,  2.05s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[281]\tvalid_0's binary_logloss: 0.00855108\tvalid_1's binary_logloss: 0.129615\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.085826\tvalid_1's binary_logloss: 0.180323\n",
            "[200]\tvalid_0's binary_logloss: 0.0258896\tvalid_1's binary_logloss: 0.139373\n",
            "[300]\tvalid_0's binary_logloss: 0.00840677\tvalid_1's binary_logloss: 0.128006\n",
            "[400]\tvalid_0's binary_logloss: 0.00283854\tvalid_1's binary_logloss: 0.128796\n",
            "Early stopping, best iteration is:\n",
            "[355]\tvalid_0's binary_logloss: 0.00452298\tvalid_1's binary_logloss: 0.126977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  43%|####2     | 3/7 [00:07<00:08,  2.05s/it]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  57%|#####7    | 4/7 [00:07<00:05,  1.99s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:20,307]\u001b[0m Trial 3 finished with value: 0.12697693147635633 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.1267842635946944.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  57%|#####7    | 4/7 [00:07<00:05,  1.99s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0995609\tvalid_1's binary_logloss: 0.193448\n",
            "[200]\tvalid_0's binary_logloss: 0.0326545\tvalid_1's binary_logloss: 0.150385\n",
            "[300]\tvalid_0's binary_logloss: 0.0115918\tvalid_1's binary_logloss: 0.140103\n",
            "[400]\tvalid_0's binary_logloss: 0.00407212\tvalid_1's binary_logloss: 0.134719\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  57%|#####7    | 4/7 [00:09<00:05,  1.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  71%|#######1  | 5/7 [00:09<00:03,  1.93s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:22,095]\u001b[0m Trial 4 finished with value: 0.13450524097571184 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.1267842635946944.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  71%|#######1  | 5/7 [00:09<00:03,  1.93s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[396]\tvalid_0's binary_logloss: 0.00423043\tvalid_1's binary_logloss: 0.134505\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0700553\tvalid_1's binary_logloss: 0.166767\n",
            "[200]\tvalid_0's binary_logloss: 0.0205571\tvalid_1's binary_logloss: 0.135652\n",
            "[300]\tvalid_0's binary_logloss: 0.00589423\tvalid_1's binary_logloss: 0.127932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  71%|#######1  | 5/7 [00:11<00:03,  1.93s/it]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  86%|########5 | 6/7 [00:11<00:01,  1.98s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:24,196]\u001b[0m Trial 5 finished with value: 0.12724253326302884 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.1267842635946944.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction, val_score: 0.126784:  86%|########5 | 6/7 [00:11<00:01,  1.98s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[296]\tvalid_0's binary_logloss: 0.00615239\tvalid_1's binary_logloss: 0.127243\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0670125\tvalid_1's binary_logloss: 0.16539\n",
            "[200]\tvalid_0's binary_logloss: 0.0194083\tvalid_1's binary_logloss: 0.134453\n",
            "[300]\tvalid_0's binary_logloss: 0.00558446\tvalid_1's binary_logloss: 0.127161\n",
            "[400]\tvalid_0's binary_logloss: 0.00161757\tvalid_1's binary_logloss: 0.12754\n",
            "Early stopping, best iteration is:\n",
            "[325]\tvalid_0's binary_logloss: 0.00406154\tvalid_1's binary_logloss: 0.125871\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction, val_score: 0.125871:  86%|########5 | 6/7 [00:14<00:01,  1.98s/it]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction, val_score: 0.125871: 100%|##########| 7/7 [00:14<00:00,  2.22s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:26,959]\u001b[0m Trial 6 finished with value: 0.1258710297072887 and parameters: {'feature_fraction': 1.0}. Best is trial 6 with value: 0.1258710297072887.\u001b[0m\n",
            "feature_fraction, val_score: 0.125871: 100%|##########| 7/7 [00:14<00:00,  2.07s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.122558\tvalid_1's binary_logloss: 0.196284\n",
            "[200]\tvalid_0's binary_logloss: 0.0606385\tvalid_1's binary_logloss: 0.157312\n",
            "[300]\tvalid_0's binary_logloss: 0.0315356\tvalid_1's binary_logloss: 0.140372\n",
            "[400]\tvalid_0's binary_logloss: 0.0160659\tvalid_1's binary_logloss: 0.131887\n",
            "[500]\tvalid_0's binary_logloss: 0.0079806\tvalid_1's binary_logloss: 0.127515\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:   0%|          | 0/20 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:   5%|5         | 1/20 [00:02<00:46,  2.44s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:29,415]\u001b[0m Trial 7 finished with value: 0.12657231999335303 and parameters: {'num_leaves': 18}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:   5%|5         | 1/20 [00:02<00:46,  2.44s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[600]\tvalid_0's binary_logloss: 0.00397002\tvalid_1's binary_logloss: 0.128906\n",
            "Early stopping, best iteration is:\n",
            "[525]\tvalid_0's binary_logloss: 0.00666372\tvalid_1's binary_logloss: 0.126572\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0108524\tvalid_1's binary_logloss: 0.138396\n",
            "[200]\tvalid_0's binary_logloss: 0.000440132\tvalid_1's binary_logloss: 0.141241\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:   5%|5         | 1/20 [00:05<00:46,  2.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  10%|#         | 2/20 [00:05<00:46,  2.56s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:32,270]\u001b[0m Trial 8 finished with value: 0.13322047677518775 and parameters: {'num_leaves': 84}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  10%|#         | 2/20 [00:05<00:46,  2.56s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[136]\tvalid_0's binary_logloss: 0.0032808\tvalid_1's binary_logloss: 0.13322\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00212958\tvalid_1's binary_logloss: 0.150486\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  10%|#         | 2/20 [00:10<00:46,  2.56s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  15%|#5        | 3/20 [00:10<00:54,  3.23s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:37,062]\u001b[0m Trial 9 finished with value: 0.1482797514383973 and parameters: {'num_leaves': 247}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  15%|#5        | 3/20 [00:10<00:54,  3.23s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[89]\tvalid_0's binary_logloss: 0.00382736\tvalid_1's binary_logloss: 0.14828\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00211612\tvalid_1's binary_logloss: 0.147665\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  15%|#5        | 3/20 [00:14<00:54,  3.23s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  20%|##        | 4/20 [00:14<00:58,  3.66s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:41,710]\u001b[0m Trial 10 finished with value: 0.1471102664512484 and parameters: {'num_leaves': 224}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  20%|##        | 4/20 [00:14<00:58,  3.66s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[94]\tvalid_0's binary_logloss: 0.00291103\tvalid_1's binary_logloss: 0.14711\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00210409\tvalid_1's binary_logloss: 0.145497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  20%|##        | 4/20 [00:19<00:58,  3.66s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  25%|##5       | 5/20 [00:19<00:59,  3.95s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:46,356]\u001b[0m Trial 11 finished with value: 0.14500972600735873 and parameters: {'num_leaves': 238}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  25%|##5       | 5/20 [00:19<00:59,  3.95s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[87]\tvalid_0's binary_logloss: 0.00420935\tvalid_1's binary_logloss: 0.14501\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0343881\tvalid_1's binary_logloss: 0.14817\n",
            "[200]\tvalid_0's binary_logloss: 0.00456805\tvalid_1's binary_logloss: 0.130268\n",
            "[300]\tvalid_0's binary_logloss: 0.000722008\tvalid_1's binary_logloss: 0.135967\n",
            "Early stopping, best iteration is:\n",
            "[218]\tvalid_0's binary_logloss: 0.00316894\tvalid_1's binary_logloss: 0.129172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  25%|##5       | 5/20 [00:22<00:59,  3.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  30%|###       | 6/20 [00:22<00:51,  3.64s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:49,272]\u001b[0m Trial 12 finished with value: 0.1291718829440485 and parameters: {'num_leaves': 47}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  30%|###       | 6/20 [00:22<00:51,  3.64s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00212331\tvalid_1's binary_logloss: 0.147737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  30%|###       | 6/20 [00:26<00:51,  3.64s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  35%|###5      | 7/20 [00:26<00:50,  3.90s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:53,785]\u001b[0m Trial 13 finished with value: 0.14636838148698864 and parameters: {'num_leaves': 222}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  35%|###5      | 7/20 [00:26<00:50,  3.90s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[90]\tvalid_0's binary_logloss: 0.00358242\tvalid_1's binary_logloss: 0.146368\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0721582\tvalid_1's binary_logloss: 0.168146\n",
            "[200]\tvalid_0's binary_logloss: 0.0226782\tvalid_1's binary_logloss: 0.137222\n",
            "[300]\tvalid_0's binary_logloss: 0.00694207\tvalid_1's binary_logloss: 0.128063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  35%|###5      | 7/20 [00:29<00:50,  3.90s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  40%|####      | 8/20 [00:29<00:40,  3.40s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:38:56,013]\u001b[0m Trial 14 finished with value: 0.1268565163771056 and parameters: {'num_leaves': 29}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  40%|####      | 8/20 [00:29<00:40,  3.40s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[400]\tvalid_0's binary_logloss: 0.00224423\tvalid_1's binary_logloss: 0.13026\n",
            "Early stopping, best iteration is:\n",
            "[313]\tvalid_0's binary_logloss: 0.00595857\tvalid_1's binary_logloss: 0.126857\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00207308\tvalid_1's binary_logloss: 0.146085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  40%|####      | 8/20 [00:33<00:40,  3.40s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  45%|####5     | 9/20 [00:33<00:41,  3.76s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:00,606]\u001b[0m Trial 15 finished with value: 0.1452964736080207 and parameters: {'num_leaves': 229}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  45%|####5     | 9/20 [00:33<00:41,  3.76s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[90]\tvalid_0's binary_logloss: 0.00353184\tvalid_1's binary_logloss: 0.145296\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00738704\tvalid_1's binary_logloss: 0.13785\n",
            "[200]\tvalid_0's binary_logloss: 0.000200569\tvalid_1's binary_logloss: 0.147984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  45%|####5     | 9/20 [00:37<00:41,  3.76s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  50%|#####     | 10/20 [00:37<00:38,  3.82s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:04,582]\u001b[0m Trial 16 finished with value: 0.1359759857185003 and parameters: {'num_leaves': 99}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  50%|#####     | 10/20 [00:37<00:38,  3.82s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[139]\tvalid_0's binary_logloss: 0.00176751\tvalid_1's binary_logloss: 0.135976\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00260851\tvalid_1's binary_logloss: 0.150389\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  50%|#####     | 10/20 [00:41<00:38,  3.82s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  55%|#####5    | 11/20 [00:41<00:34,  3.85s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:08,500]\u001b[0m Trial 17 finished with value: 0.14981533578628672 and parameters: {'num_leaves': 168}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  55%|#####5    | 11/20 [00:41<00:34,  3.85s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[93]\tvalid_0's binary_logloss: 0.00368459\tvalid_1's binary_logloss: 0.149815\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.242119\tvalid_1's binary_logloss: 0.284466\n",
            "[200]\tvalid_0's binary_logloss: 0.175308\tvalid_1's binary_logloss: 0.231566\n",
            "[300]\tvalid_0's binary_logloss: 0.134912\tvalid_1's binary_logloss: 0.202879\n",
            "[400]\tvalid_0's binary_logloss: 0.105221\tvalid_1's binary_logloss: 0.183483\n",
            "[500]\tvalid_0's binary_logloss: 0.082552\tvalid_1's binary_logloss: 0.16795\n",
            "[600]\tvalid_0's binary_logloss: 0.0657207\tvalid_1's binary_logloss: 0.15778\n",
            "[700]\tvalid_0's binary_logloss: 0.0530545\tvalid_1's binary_logloss: 0.15199\n",
            "[800]\tvalid_0's binary_logloss: 0.042326\tvalid_1's binary_logloss: 0.146314\n",
            "[900]\tvalid_0's binary_logloss: 0.0338007\tvalid_1's binary_logloss: 0.141005\n",
            "[1000]\tvalid_0's binary_logloss: 0.0273425\tvalid_1's binary_logloss: 0.139005\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's binary_logloss: 0.0273425\tvalid_1's binary_logloss: 0.139005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  55%|#####5    | 11/20 [00:43<00:34,  3.85s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  60%|######    | 12/20 [00:43<00:26,  3.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:10,726]\u001b[0m Trial 18 finished with value: 0.1390050484917149 and parameters: {'num_leaves': 7}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  60%|######    | 12/20 [00:43<00:26,  3.36s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.289129\tvalid_1's binary_logloss: 0.321149\n",
            "[200]\tvalid_0's binary_logloss: 0.225408\tvalid_1's binary_logloss: 0.268838\n",
            "[300]\tvalid_0's binary_logloss: 0.18498\tvalid_1's binary_logloss: 0.23633\n",
            "[400]\tvalid_0's binary_logloss: 0.154174\tvalid_1's binary_logloss: 0.212186\n",
            "[500]\tvalid_0's binary_logloss: 0.132382\tvalid_1's binary_logloss: 0.198369\n",
            "[600]\tvalid_0's binary_logloss: 0.114582\tvalid_1's binary_logloss: 0.18864\n",
            "[700]\tvalid_0's binary_logloss: 0.0980433\tvalid_1's binary_logloss: 0.178132\n",
            "[800]\tvalid_0's binary_logloss: 0.0855587\tvalid_1's binary_logloss: 0.170284\n",
            "[900]\tvalid_0's binary_logloss: 0.0736135\tvalid_1's binary_logloss: 0.162715\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  60%|######    | 12/20 [00:45<00:26,  3.36s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  65%|######5   | 13/20 [00:45<00:20,  2.93s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:12,653]\u001b[0m Trial 19 finished with value: 0.15488780789240938 and parameters: {'num_leaves': 5}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  65%|######5   | 13/20 [00:45<00:20,  2.93s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1000]\tvalid_0's binary_logloss: 0.062534\tvalid_1's binary_logloss: 0.154888\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\tvalid_0's binary_logloss: 0.062534\tvalid_1's binary_logloss: 0.154888\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0542946\tvalid_1's binary_logloss: 0.159296\n",
            "[200]\tvalid_0's binary_logloss: 0.0122362\tvalid_1's binary_logloss: 0.132438\n",
            "[300]\tvalid_0's binary_logloss: 0.00287122\tvalid_1's binary_logloss: 0.128661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  65%|######5   | 13/20 [00:48<00:20,  2.93s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  70%|#######   | 14/20 [00:48<00:16,  2.76s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:15,005]\u001b[0m Trial 20 finished with value: 0.12736890756239522 and parameters: {'num_leaves': 36}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  70%|#######   | 14/20 [00:48<00:16,  2.76s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[268]\tvalid_0's binary_logloss: 0.00443585\tvalid_1's binary_logloss: 0.127369\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0262486\tvalid_1's binary_logloss: 0.143985\n",
            "[200]\tvalid_0's binary_logloss: 0.00265559\tvalid_1's binary_logloss: 0.131761\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  70%|#######   | 14/20 [00:50<00:16,  2.76s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  75%|#######5  | 15/20 [00:50<00:13,  2.67s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:17,451]\u001b[0m Trial 21 finished with value: 0.12987350145916515 and parameters: {'num_leaves': 54}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  75%|#######5  | 15/20 [00:50<00:13,  2.67s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[176]\tvalid_0's binary_logloss: 0.00450925\tvalid_1's binary_logloss: 0.129874\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00317166\tvalid_1's binary_logloss: 0.140787\n",
            "[200]\tvalid_0's binary_logloss: 3.16907e-05\tvalid_1's binary_logloss: 0.166684\n",
            "Early stopping, best iteration is:\n",
            "[110]\tvalid_0's binary_logloss: 0.00197772\tvalid_1's binary_logloss: 0.139581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  75%|#######5  | 15/20 [00:54<00:13,  2.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  80%|########  | 16/20 [00:54<00:11,  2.95s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:21,077]\u001b[0m Trial 22 finished with value: 0.13958140799344204 and parameters: {'num_leaves': 148}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  80%|########  | 16/20 [00:54<00:11,  2.95s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.118453\tvalid_1's binary_logloss: 0.195297\n",
            "[200]\tvalid_0's binary_logloss: 0.056597\tvalid_1's binary_logloss: 0.158177\n",
            "[300]\tvalid_0's binary_logloss: 0.0266931\tvalid_1's binary_logloss: 0.139292\n",
            "[400]\tvalid_0's binary_logloss: 0.012967\tvalid_1's binary_logloss: 0.130536\n",
            "[500]\tvalid_0's binary_logloss: 0.00625867\tvalid_1's binary_logloss: 0.129047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  80%|########  | 16/20 [00:56<00:11,  2.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.125871:  85%|########5 | 17/20 [00:56<00:08,  2.81s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:23,563]\u001b[0m Trial 23 finished with value: 0.12845765824538907 and parameters: {'num_leaves': 19}. Best is trial 7 with value: 0.12657231999335303.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.125871:  85%|########5 | 17/20 [00:56<00:08,  2.81s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[600]\tvalid_0's binary_logloss: 0.00311414\tvalid_1's binary_logloss: 0.1319\n",
            "Early stopping, best iteration is:\n",
            "[525]\tvalid_0's binary_logloss: 0.0052811\tvalid_1's binary_logloss: 0.128458\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0121489\tvalid_1's binary_logloss: 0.131919\n",
            "[200]\tvalid_0's binary_logloss: 0.000570461\tvalid_1's binary_logloss: 0.133385\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.124699:  85%|########5 | 17/20 [00:59<00:08,  2.81s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.124699:  90%|######### | 18/20 [00:59<00:05,  2.82s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:26,402]\u001b[0m Trial 24 finished with value: 0.12469855805577222 and parameters: {'num_leaves': 79}. Best is trial 24 with value: 0.12469855805577222.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.124699:  90%|######### | 18/20 [00:59<00:05,  2.82s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[142]\tvalid_0's binary_logloss: 0.00320091\tvalid_1's binary_logloss: 0.124699\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.00807896\tvalid_1's binary_logloss: 0.136588\n",
            "[200]\tvalid_0's binary_logloss: 0.000251805\tvalid_1's binary_logloss: 0.148146\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.124699:  90%|######### | 18/20 [01:02<00:05,  2.82s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.124699:  95%|#########5| 19/20 [01:02<00:02,  2.88s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:29,414]\u001b[0m Trial 25 finished with value: 0.13373629964652547 and parameters: {'num_leaves': 95}. Best is trial 24 with value: 0.12469855805577222.\u001b[0m\n",
            "\n",
            "\n",
            "num_leaves, val_score: 0.124699:  95%|#########5| 19/20 [01:02<00:02,  2.88s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[126]\tvalid_0's binary_logloss: 0.00318981\tvalid_1's binary_logloss: 0.133736\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0150278\tvalid_1's binary_logloss: 0.133367\n",
            "[200]\tvalid_0's binary_logloss: 0.000872214\tvalid_1's binary_logloss: 0.129906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "num_leaves, val_score: 0.124699:  95%|#########5| 19/20 [01:05<00:02,  2.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "num_leaves, val_score: 0.124699: 100%|##########| 20/20 [01:05<00:00,  2.84s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:32,167]\u001b[0m Trial 26 finished with value: 0.12635986065312171 and parameters: {'num_leaves': 71}. Best is trial 24 with value: 0.12469855805577222.\u001b[0m\n",
            "num_leaves, val_score: 0.124699: 100%|##########| 20/20 [01:05<00:00,  3.26s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124699:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[153]\tvalid_0's binary_logloss: 0.00322334\tvalid_1's binary_logloss: 0.12636\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.014738\tvalid_1's binary_logloss: 0.133691\n",
            "[200]\tvalid_0's binary_logloss: 0.000793875\tvalid_1's binary_logloss: 0.129304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124699:   0%|          | 0/10 [00:02<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124699:  10%|#         | 1/10 [00:02<00:25,  2.86s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:35,042]\u001b[0m Trial 27 finished with value: 0.1253406928238815 and parameters: {'bagging_fraction': 0.6900815061766645, 'bagging_freq': 6}. Best is trial 27 with value: 0.1253406928238815.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124699:  10%|#         | 1/10 [00:02<00:25,  2.86s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[143]\tvalid_0's binary_logloss: 0.00397407\tvalid_1's binary_logloss: 0.125341\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0121239\tvalid_1's binary_logloss: 0.135092\n",
            "[200]\tvalid_0's binary_logloss: 0.000548013\tvalid_1's binary_logloss: 0.13402\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124699:  10%|#         | 1/10 [00:05<00:25,  2.86s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124699:  20%|##        | 2/10 [00:05<00:23,  2.88s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:37,972]\u001b[0m Trial 28 finished with value: 0.12685219232260944 and parameters: {'bagging_fraction': 0.8472482843433509, 'bagging_freq': 1}. Best is trial 27 with value: 0.1253406928238815.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124699:  20%|##        | 2/10 [00:05<00:23,  2.88s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[148]\tvalid_0's binary_logloss: 0.00268063\tvalid_1's binary_logloss: 0.126852\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0167784\tvalid_1's binary_logloss: 0.133953\n",
            "[200]\tvalid_0's binary_logloss: 0.00116408\tvalid_1's binary_logloss: 0.126971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  20%|##        | 2/10 [00:09<00:23,  2.88s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342:  30%|###       | 3/10 [00:09<00:21,  3.07s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:41,468]\u001b[0m Trial 29 finished with value: 0.124341634677393 and parameters: {'bagging_fraction': 0.5522670384439083, 'bagging_freq': 3}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  30%|###       | 3/10 [00:09<00:21,  3.07s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[181]\tvalid_0's binary_logloss: 0.00184544\tvalid_1's binary_logloss: 0.124342\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0124083\tvalid_1's binary_logloss: 0.136634\n",
            "[200]\tvalid_0's binary_logloss: 0.000559782\tvalid_1's binary_logloss: 0.138657\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  30%|###       | 3/10 [00:12<00:21,  3.07s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342:  40%|####      | 4/10 [00:12<00:19,  3.18s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:44,930]\u001b[0m Trial 30 finished with value: 0.131792327720223 and parameters: {'bagging_fraction': 0.9424749125586375, 'bagging_freq': 6}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  40%|####      | 4/10 [00:12<00:19,  3.18s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[144]\tvalid_0's binary_logloss: 0.00305411\tvalid_1's binary_logloss: 0.131792\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0168921\tvalid_1's binary_logloss: 0.13181\n",
            "[200]\tvalid_0's binary_logloss: 0.00123708\tvalid_1's binary_logloss: 0.129147\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  40%|####      | 4/10 [00:15<00:19,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342:  50%|#####     | 5/10 [00:15<00:15,  3.19s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:48,146]\u001b[0m Trial 31 finished with value: 0.12460087384409821 and parameters: {'bagging_fraction': 0.506091870024153, 'bagging_freq': 1}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  50%|#####     | 5/10 [00:15<00:15,  3.19s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[146]\tvalid_0's binary_logloss: 0.00481116\tvalid_1's binary_logloss: 0.124601\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.013276\tvalid_1's binary_logloss: 0.133563\n",
            "[200]\tvalid_0's binary_logloss: 0.0006565\tvalid_1's binary_logloss: 0.136751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  50%|#####     | 5/10 [00:18<00:15,  3.19s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342:  60%|######    | 6/10 [00:18<00:12,  3.12s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:51,103]\u001b[0m Trial 32 finished with value: 0.1295390005372379 and parameters: {'bagging_fraction': 0.7609564751420113, 'bagging_freq': 3}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  60%|######    | 6/10 [00:18<00:12,  3.12s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[144]\tvalid_0's binary_logloss: 0.00340978\tvalid_1's binary_logloss: 0.129539\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0133803\tvalid_1's binary_logloss: 0.135992\n",
            "[200]\tvalid_0's binary_logloss: 0.000669187\tvalid_1's binary_logloss: 0.134496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  60%|######    | 6/10 [00:21<00:12,  3.12s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342:  70%|#######   | 7/10 [00:21<00:09,  3.03s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:53,920]\u001b[0m Trial 33 finished with value: 0.12870750492233127 and parameters: {'bagging_fraction': 0.7303107072506694, 'bagging_freq': 2}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  70%|#######   | 7/10 [00:21<00:09,  3.03s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[135]\tvalid_0's binary_logloss: 0.00453483\tvalid_1's binary_logloss: 0.128708\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0156997\tvalid_1's binary_logloss: 0.145473\n",
            "[200]\tvalid_0's binary_logloss: 0.000927668\tvalid_1's binary_logloss: 0.143209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  70%|#######   | 7/10 [00:24<00:09,  3.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342:  80%|########  | 8/10 [00:24<00:05,  2.96s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:39:56,726]\u001b[0m Trial 34 finished with value: 0.13710999424377587 and parameters: {'bagging_fraction': 0.6222821929026159, 'bagging_freq': 4}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  80%|########  | 8/10 [00:24<00:05,  2.96s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[145]\tvalid_0's binary_logloss: 0.00435213\tvalid_1's binary_logloss: 0.13711\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0134556\tvalid_1's binary_logloss: 0.138021\n",
            "[200]\tvalid_0's binary_logloss: 0.000663547\tvalid_1's binary_logloss: 0.131107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  80%|########  | 8/10 [00:27<00:05,  2.96s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342:  90%|######### | 9/10 [00:27<00:03,  3.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:00,026]\u001b[0m Trial 35 finished with value: 0.128576906527861 and parameters: {'bagging_fraction': 0.7993209230065959, 'bagging_freq': 7}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  90%|######### | 9/10 [00:27<00:03,  3.06s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[171]\tvalid_0's binary_logloss: 0.00155561\tvalid_1's binary_logloss: 0.128577\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.013326\tvalid_1's binary_logloss: 0.135931\n",
            "[200]\tvalid_0's binary_logloss: 0.000648961\tvalid_1's binary_logloss: 0.131627\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "bagging, val_score: 0.124342:  90%|######### | 9/10 [00:31<00:03,  3.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "bagging, val_score: 0.124342: 100%|##########| 10/10 [00:31<00:00,  3.10s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:03,224]\u001b[0m Trial 36 finished with value: 0.12543411966086443 and parameters: {'bagging_fraction': 0.7823023024503988, 'bagging_freq': 5}. Best is trial 29 with value: 0.124341634677393.\u001b[0m\n",
            "bagging, val_score: 0.124342: 100%|##########| 10/10 [00:31<00:00,  3.11s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.124342:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[163]\tvalid_0's binary_logloss: 0.00194708\tvalid_1's binary_logloss: 0.125434\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0167784\tvalid_1's binary_logloss: 0.133953\n",
            "[200]\tvalid_0's binary_logloss: 0.00116408\tvalid_1's binary_logloss: 0.126971\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.124342:   0%|          | 0/3 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.124342:  33%|###3      | 1/3 [00:03<00:06,  3.45s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:06,691]\u001b[0m Trial 37 finished with value: 0.124341634677393 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.124341634677393.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.124342:  33%|###3      | 1/3 [00:03<00:06,  3.45s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[181]\tvalid_0's binary_logloss: 0.00184544\tvalid_1's binary_logloss: 0.124342\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0182152\tvalid_1's binary_logloss: 0.136811\n",
            "[200]\tvalid_0's binary_logloss: 0.00126106\tvalid_1's binary_logloss: 0.124647\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.123269:  33%|###3      | 1/3 [00:06<00:06,  3.45s/it]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.123269:  67%|######6   | 2/3 [00:06<00:03,  3.33s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:09,732]\u001b[0m Trial 38 finished with value: 0.12326948212070538 and parameters: {'feature_fraction': 0.92}. Best is trial 38 with value: 0.12326948212070538.\u001b[0m\n",
            "\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.123269:  67%|######6   | 2/3 [00:06<00:03,  3.33s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[183]\tvalid_0's binary_logloss: 0.00194569\tvalid_1's binary_logloss: 0.123269\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0172516\tvalid_1's binary_logloss: 0.141374\n",
            "[200]\tvalid_0's binary_logloss: 0.00120967\tvalid_1's binary_logloss: 0.13505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.123269:  67%|######6   | 2/3 [00:09<00:03,  3.33s/it]\u001b[A\u001b[A\n",
            "\n",
            "feature_fraction_stage2, val_score: 0.123269: 100%|##########| 3/3 [00:09<00:00,  3.21s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:12,666]\u001b[0m Trial 39 finished with value: 0.13239515420800846 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 38 with value: 0.12326948212070538.\u001b[0m\n",
            "feature_fraction_stage2, val_score: 0.123269: 100%|##########| 3/3 [00:09<00:00,  3.15s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.123269:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[167]\tvalid_0's binary_logloss: 0.00283815\tvalid_1's binary_logloss: 0.132395\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0180464\tvalid_1's binary_logloss: 0.132889\n",
            "[200]\tvalid_0's binary_logloss: 0.00124839\tvalid_1's binary_logloss: 0.128347\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.123269:   0%|          | 0/20 [00:03<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.123269:   5%|5         | 1/20 [00:03<01:06,  3.52s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:16,206]\u001b[0m Trial 40 finished with value: 0.12579788711255332 and parameters: {'lambda_l1': 1.0348527137124406e-08, 'lambda_l2': 0.0002049357238428087}. Best is trial 40 with value: 0.12579788711255332.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.123269:   5%|5         | 1/20 [00:03<01:06,  3.52s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[164]\tvalid_0's binary_logloss: 0.00317321\tvalid_1's binary_logloss: 0.125798\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0181192\tvalid_1's binary_logloss: 0.138983\n",
            "[200]\tvalid_0's binary_logloss: 0.00124084\tvalid_1's binary_logloss: 0.131339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.123269:   5%|5         | 1/20 [00:06<01:06,  3.52s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.123269:  10%|#         | 2/20 [00:06<01:01,  3.44s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:19,464]\u001b[0m Trial 41 finished with value: 0.1281853322272927 and parameters: {'lambda_l1': 8.707498725460752e-06, 'lambda_l2': 0.001653551777293049}. Best is trial 40 with value: 0.12579788711255332.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.123269:  10%|#         | 2/20 [00:06<01:01,  3.44s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[164]\tvalid_0's binary_logloss: 0.00316202\tvalid_1's binary_logloss: 0.128185\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0179499\tvalid_1's binary_logloss: 0.137667\n",
            "[200]\tvalid_0's binary_logloss: 0.00124045\tvalid_1's binary_logloss: 0.130092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.123269:  10%|#         | 2/20 [00:09<01:01,  3.44s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.123269:  15%|#5        | 3/20 [00:09<00:56,  3.32s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:22,506]\u001b[0m Trial 42 finished with value: 0.1270431104552948 and parameters: {'lambda_l1': 8.584482617097685e-05, 'lambda_l2': 1.718302213896784e-05}. Best is trial 40 with value: 0.12579788711255332.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.123269:  15%|#5        | 3/20 [00:09<00:56,  3.32s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[150]\tvalid_0's binary_logloss: 0.00456475\tvalid_1's binary_logloss: 0.127043\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0213594\tvalid_1's binary_logloss: 0.139572\n",
            "[200]\tvalid_0's binary_logloss: 0.00414709\tvalid_1's binary_logloss: 0.123623\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.122651:  15%|#5        | 3/20 [00:12<00:56,  3.32s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.122651:  20%|##        | 4/20 [00:12<00:50,  3.18s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:25,358]\u001b[0m Trial 43 finished with value: 0.12265146163273326 and parameters: {'lambda_l1': 0.13998076360248898, 'lambda_l2': 0.0001759682824632604}. Best is trial 43 with value: 0.12265146163273326.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[300]\tvalid_0's binary_logloss: 0.00202356\tvalid_1's binary_logloss: 0.125554\n",
            "Early stopping, best iteration is:\n",
            "[214]\tvalid_0's binary_logloss: 0.0036051\tvalid_1's binary_logloss: 0.122651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.122651:  20%|##        | 4/20 [00:12<00:50,  3.18s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0466559\tvalid_1's binary_logloss: 0.149399\n",
            "[200]\tvalid_0's binary_logloss: 0.019821\tvalid_1's binary_logloss: 0.125507\n",
            "[300]\tvalid_0's binary_logloss: 0.014047\tvalid_1's binary_logloss: 0.121881\n",
            "[400]\tvalid_0's binary_logloss: 0.0116231\tvalid_1's binary_logloss: 0.121956\n",
            "[500]\tvalid_0's binary_logloss: 0.01097\tvalid_1's binary_logloss: 0.121808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  20%|##        | 4/20 [00:15<00:50,  3.18s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  25%|##5       | 5/20 [00:15<00:45,  3.03s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:28,048]\u001b[0m Trial 44 finished with value: 0.12115511027382367 and parameters: {'lambda_l1': 1.3404651024897698, 'lambda_l2': 0.003811452189442354}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  25%|##5       | 5/20 [00:15<00:45,  3.03s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[428]\tvalid_0's binary_logloss: 0.0112866\tvalid_1's binary_logloss: 0.121155\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0179837\tvalid_1's binary_logloss: 0.139469\n",
            "[200]\tvalid_0's binary_logloss: 0.00121513\tvalid_1's binary_logloss: 0.131312\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  25%|##5       | 5/20 [00:18<00:45,  3.03s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  30%|###       | 6/20 [00:18<00:42,  3.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:31,160]\u001b[0m Trial 45 finished with value: 0.12881837704319776 and parameters: {'lambda_l1': 1.081486135520939e-06, 'lambda_l2': 7.287970747252476e-06}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  30%|###       | 6/20 [00:18<00:42,  3.06s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[152]\tvalid_0's binary_logloss: 0.00434798\tvalid_1's binary_logloss: 0.128818\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0181696\tvalid_1's binary_logloss: 0.136643\n",
            "[200]\tvalid_0's binary_logloss: 0.00152459\tvalid_1's binary_logloss: 0.12629\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  30%|###       | 6/20 [00:22<00:42,  3.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  35%|###5      | 7/20 [00:22<00:44,  3.39s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:35,336]\u001b[0m Trial 46 finished with value: 0.12510984086573684 and parameters: {'lambda_l1': 0.010519382735496175, 'lambda_l2': 0.00011801456084622971}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  35%|###5      | 7/20 [00:22<00:44,  3.39s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[300]\tvalid_0's binary_logloss: 0.000316804\tvalid_1's binary_logloss: 0.13027\n",
            "Early stopping, best iteration is:\n",
            "[205]\tvalid_0's binary_logloss: 0.00136698\tvalid_1's binary_logloss: 0.12511\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0180426\tvalid_1's binary_logloss: 0.136847\n",
            "[200]\tvalid_0's binary_logloss: 0.0012721\tvalid_1's binary_logloss: 0.13345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  35%|###5      | 7/20 [00:26<00:44,  3.39s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  40%|####      | 8/20 [00:26<00:43,  3.60s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:39,436]\u001b[0m Trial 47 finished with value: 0.13080829884115427 and parameters: {'lambda_l1': 7.462277298416262e-08, 'lambda_l2': 7.153436631067145e-06}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  40%|####      | 8/20 [00:26<00:43,  3.60s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[181]\tvalid_0's binary_logloss: 0.00207401\tvalid_1's binary_logloss: 0.130808\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0180828\tvalid_1's binary_logloss: 0.137805\n",
            "[200]\tvalid_0's binary_logloss: 0.00126067\tvalid_1's binary_logloss: 0.129329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  40%|####      | 8/20 [00:30<00:43,  3.60s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  45%|####5     | 9/20 [00:30<00:39,  3.58s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:42,976]\u001b[0m Trial 48 finished with value: 0.12503711974061626 and parameters: {'lambda_l1': 2.137798989981727e-06, 'lambda_l2': 0.0009171508559301906}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  45%|####5     | 9/20 [00:30<00:39,  3.58s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[163]\tvalid_0's binary_logloss: 0.00328423\tvalid_1's binary_logloss: 0.125037\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0189787\tvalid_1's binary_logloss: 0.138704\n",
            "[200]\tvalid_0's binary_logloss: 0.00167035\tvalid_1's binary_logloss: 0.129277\n",
            "[300]\tvalid_0's binary_logloss: 0.000330497\tvalid_1's binary_logloss: 0.133104\n",
            "Early stopping, best iteration is:\n",
            "[212]\tvalid_0's binary_logloss: 0.00131383\tvalid_1's binary_logloss: 0.127427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  45%|####5     | 9/20 [00:34<00:39,  3.58s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  50%|#####     | 10/20 [00:34<00:36,  3.67s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:46,841]\u001b[0m Trial 49 finished with value: 0.12742747071917257 and parameters: {'lambda_l1': 5.95532995758826e-07, 'lambda_l2': 0.0278348086996086}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  50%|#####     | 10/20 [00:34<00:36,  3.67s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.119464\tvalid_1's binary_logloss: 0.194027\n",
            "[200]\tvalid_0's binary_logloss: 0.0684737\tvalid_1's binary_logloss: 0.155648\n",
            "[300]\tvalid_0's binary_logloss: 0.0511617\tvalid_1's binary_logloss: 0.143297\n",
            "[400]\tvalid_0's binary_logloss: 0.0429421\tvalid_1's binary_logloss: 0.13961\n",
            "[500]\tvalid_0's binary_logloss: 0.037959\tvalid_1's binary_logloss: 0.137421\n",
            "[600]\tvalid_0's binary_logloss: 0.035381\tvalid_1's binary_logloss: 0.136211\n",
            "[700]\tvalid_0's binary_logloss: 0.032916\tvalid_1's binary_logloss: 0.135225\n",
            "Early stopping, best iteration is:\n",
            "[699]\tvalid_0's binary_logloss: 0.0329723\tvalid_1's binary_logloss: 0.135167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  50%|#####     | 10/20 [00:37<00:36,  3.67s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  55%|#####5    | 11/20 [00:37<00:32,  3.63s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:50,383]\u001b[0m Trial 50 finished with value: 0.13516651686465098 and parameters: {'lambda_l1': 4.008378390053312, 'lambda_l2': 7.62919941717154}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  55%|#####5    | 11/20 [00:37<00:32,  3.63s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0373656\tvalid_1's binary_logloss: 0.147131\n",
            "[200]\tvalid_0's binary_logloss: 0.0138543\tvalid_1's binary_logloss: 0.126112\n",
            "[300]\tvalid_0's binary_logloss: 0.00945551\tvalid_1's binary_logloss: 0.121792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  55%|#####5    | 11/20 [00:40<00:32,  3.63s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  60%|######    | 12/20 [00:40<00:26,  3.30s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:52,900]\u001b[0m Trial 51 finished with value: 0.12129631140286776 and parameters: {'lambda_l1': 0.8528914000124972, 'lambda_l2': 3.5705145440529955e-08}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  60%|######    | 12/20 [00:40<00:26,  3.30s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[286]\tvalid_0's binary_logloss: 0.00977541\tvalid_1's binary_logloss: 0.121296\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.146739\tvalid_1's binary_logloss: 0.213465\n",
            "[200]\tvalid_0's binary_logloss: 0.108125\tvalid_1's binary_logloss: 0.184949\n",
            "[300]\tvalid_0's binary_logloss: 0.0975798\tvalid_1's binary_logloss: 0.178102\n",
            "[400]\tvalid_0's binary_logloss: 0.0939627\tvalid_1's binary_logloss: 0.176142\n",
            "Early stopping, best iteration is:\n",
            "[338]\tvalid_0's binary_logloss: 0.0939665\tvalid_1's binary_logloss: 0.176136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  60%|######    | 12/20 [00:41<00:26,  3.30s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  65%|######5   | 13/20 [00:41<00:19,  2.82s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:54,625]\u001b[0m Trial 52 finished with value: 0.17613577039971973 and parameters: {'lambda_l1': 9.373309588895324, 'lambda_l2': 2.1765799346899938e-08}. Best is trial 44 with value: 0.12115511027382367.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.121155:  65%|######5   | 13/20 [00:41<00:19,  2.82s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0216779\tvalid_1's binary_logloss: 0.139058\n",
            "[200]\tvalid_0's binary_logloss: 0.00405677\tvalid_1's binary_logloss: 0.12027\n",
            "[300]\tvalid_0's binary_logloss: 0.00195915\tvalid_1's binary_logloss: 0.119834\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.119169:  65%|######5   | 13/20 [00:45<00:19,  2.82s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.119169:  70%|#######   | 14/20 [00:45<00:17,  2.95s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:40:57,862]\u001b[0m Trial 53 finished with value: 0.11916896864045334 and parameters: {'lambda_l1': 0.1371644247309759, 'lambda_l2': 1.603354314341163e-08}. Best is trial 53 with value: 0.11916896864045334.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.119169:  70%|#######   | 14/20 [00:45<00:17,  2.95s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[285]\tvalid_0's binary_logloss: 0.00210365\tvalid_1's binary_logloss: 0.119169\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0214544\tvalid_1's binary_logloss: 0.133305\n",
            "[200]\tvalid_0's binary_logloss: 0.00314214\tvalid_1's binary_logloss: 0.11814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[300]\tvalid_0's binary_logloss: 0.00108072\tvalid_1's binary_logloss: 0.119619\n",
            "Early stopping, best iteration is:\n",
            "[213]\tvalid_0's binary_logloss: 0.00264854\tvalid_1's binary_logloss: 0.117277\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rregularization_factors, val_score: 0.117277:  70%|#######   | 14/20 [00:48<00:17,  2.95s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.117277:  75%|#######5  | 15/20 [00:48<00:15,  3.14s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:01,457]\u001b[0m Trial 54 finished with value: 0.11727702941222083 and parameters: {'lambda_l1': 0.008329977350594361, 'lambda_l2': 0.16788527719858534}. Best is trial 54 with value: 0.11727702941222083.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.117277:  75%|#######5  | 15/20 [00:48<00:15,  3.14s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0337085\tvalid_1's binary_logloss: 0.144872\n",
            "[200]\tvalid_0's binary_logloss: 0.00847479\tvalid_1's binary_logloss: 0.121629\n",
            "[300]\tvalid_0's binary_logloss: 0.00373924\tvalid_1's binary_logloss: 0.118283\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.117216:  75%|#######5  | 15/20 [00:52<00:15,  3.14s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.117216:  80%|########  | 16/20 [00:52<00:13,  3.29s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:05,071]\u001b[0m Trial 55 finished with value: 0.1172158664178025 and parameters: {'lambda_l1': 0.005721349413292561, 'lambda_l2': 1.1064494690156204}. Best is trial 55 with value: 0.1172158664178025.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.117216:  80%|########  | 16/20 [00:52<00:13,  3.29s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[281]\tvalid_0's binary_logloss: 0.0042715\tvalid_1's binary_logloss: 0.117216\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0465332\tvalid_1's binary_logloss: 0.149177\n",
            "[200]\tvalid_0's binary_logloss: 0.014409\tvalid_1's binary_logloss: 0.121679\n",
            "[300]\tvalid_0's binary_logloss: 0.00702917\tvalid_1's binary_logloss: 0.11773\n",
            "[400]\tvalid_0's binary_logloss: 0.00439961\tvalid_1's binary_logloss: 0.11655\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.116145:  80%|########  | 16/20 [00:56<00:13,  3.29s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.116145:  85%|########5 | 17/20 [00:56<00:10,  3.57s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:09,297]\u001b[0m Trial 56 finished with value: 0.11614534045035568 and parameters: {'lambda_l1': 0.0031372441677219136, 'lambda_l2': 2.493170624975375}. Best is trial 56 with value: 0.11614534045035568.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.116145:  85%|########5 | 17/20 [00:56<00:10,  3.57s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[378]\tvalid_0's binary_logloss: 0.00480696\tvalid_1's binary_logloss: 0.116145\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0460522\tvalid_1's binary_logloss: 0.144808\n",
            "[200]\tvalid_0's binary_logloss: 0.0140726\tvalid_1's binary_logloss: 0.117725\n",
            "[300]\tvalid_0's binary_logloss: 0.00693073\tvalid_1's binary_logloss: 0.112742\n",
            "[400]\tvalid_0's binary_logloss: 0.00439242\tvalid_1's binary_logloss: 0.112298\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.111484:  85%|########5 | 17/20 [01:00<00:10,  3.57s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.111484:  90%|######### | 18/20 [01:00<00:07,  3.76s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:13,513]\u001b[0m Trial 57 finished with value: 0.11148377168111051 and parameters: {'lambda_l1': 0.0009868172868937799, 'lambda_l2': 2.4843451284052835}. Best is trial 57 with value: 0.11148377168111051.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.111484:  90%|######### | 18/20 [01:00<00:07,  3.76s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[378]\tvalid_0's binary_logloss: 0.00479296\tvalid_1's binary_logloss: 0.111484\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0657165\tvalid_1's binary_logloss: 0.160953\n",
            "[200]\tvalid_0's binary_logloss: 0.0246156\tvalid_1's binary_logloss: 0.12745\n",
            "[300]\tvalid_0's binary_logloss: 0.0131925\tvalid_1's binary_logloss: 0.121428\n",
            "[400]\tvalid_0's binary_logloss: 0.00860767\tvalid_1's binary_logloss: 0.119006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.111484:  90%|######### | 18/20 [01:05<00:07,  3.76s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.111484:  95%|#########5| 19/20 [01:05<00:03,  3.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[396]\tvalid_0's binary_logloss: 0.00871883\tvalid_1's binary_logloss: 0.118721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:18,052]\u001b[0m Trial 58 finished with value: 0.11872065284275873 and parameters: {'lambda_l1': 0.00037880876256679525, 'lambda_l2': 5.462649766586803}. Best is trial 57 with value: 0.11148377168111051.\u001b[0m\n",
            "\n",
            "\n",
            "regularization_factors, val_score: 0.111484:  95%|#########5| 19/20 [01:05<00:03,  3.99s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0217963\tvalid_1's binary_logloss: 0.141668\n",
            "[200]\tvalid_0's binary_logloss: 0.00324904\tvalid_1's binary_logloss: 0.124502\n",
            "[300]\tvalid_0's binary_logloss: 0.00107873\tvalid_1's binary_logloss: 0.125211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "regularization_factors, val_score: 0.111484:  95%|#########5| 19/20 [01:09<00:03,  3.99s/it]\u001b[A\u001b[A\n",
            "\n",
            "regularization_factors, val_score: 0.111484: 100%|##########| 20/20 [01:09<00:00,  3.94s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:21,854]\u001b[0m Trial 59 finished with value: 0.12385060513684061 and parameters: {'lambda_l1': 5.9179753553479954e-05, 'lambda_l2': 0.19607598758437675}. Best is trial 57 with value: 0.11148377168111051.\u001b[0m\n",
            "regularization_factors, val_score: 0.111484: 100%|##########| 20/20 [01:09<00:00,  3.46s/it]\n",
            "\n",
            "\n",
            "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:   0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[270]\tvalid_0's binary_logloss: 0.00140888\tvalid_1's binary_logloss: 0.123851\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0716062\tvalid_1's binary_logloss: 0.160789\n",
            "[200]\tvalid_0's binary_logloss: 0.0246154\tvalid_1's binary_logloss: 0.129524\n",
            "[300]\tvalid_0's binary_logloss: 0.0120498\tvalid_1's binary_logloss: 0.122863\n",
            "[400]\tvalid_0's binary_logloss: 0.0074195\tvalid_1's binary_logloss: 0.120749\n",
            "[500]\tvalid_0's binary_logloss: 0.0051208\tvalid_1's binary_logloss: 0.120066\n",
            "[600]\tvalid_0's binary_logloss: 0.00378489\tvalid_1's binary_logloss: 0.119654\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:   0%|          | 0/5 [00:04<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  20%|##        | 1/5 [00:04<00:17,  4.31s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:26,194]\u001b[0m Trial 60 finished with value: 0.11927011248326207 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.11927011248326207.\u001b[0m\n",
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  20%|##        | 1/5 [00:04<00:17,  4.31s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[583]\tvalid_0's binary_logloss: 0.00396653\tvalid_1's binary_logloss: 0.11927\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0420807\tvalid_1's binary_logloss: 0.151918\n",
            "[200]\tvalid_0's binary_logloss: 0.0126405\tvalid_1's binary_logloss: 0.123638\n",
            "[300]\tvalid_0's binary_logloss: 0.00609407\tvalid_1's binary_logloss: 0.120428\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  20%|##        | 1/5 [00:08<00:17,  4.31s/it]\u001b[A\u001b[A\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  40%|####      | 2/5 [00:08<00:12,  4.25s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:30,297]\u001b[0m Trial 61 finished with value: 0.11928849681075145 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.11927011248326207.\u001b[0m\n",
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  40%|####      | 2/5 [00:08<00:12,  4.25s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[282]\tvalid_0's binary_logloss: 0.00678486\tvalid_1's binary_logloss: 0.119288\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0496995\tvalid_1's binary_logloss: 0.154284\n",
            "[200]\tvalid_0's binary_logloss: 0.0156126\tvalid_1's binary_logloss: 0.125966\n",
            "[300]\tvalid_0's binary_logloss: 0.00770722\tvalid_1's binary_logloss: 0.122905\n",
            "[400]\tvalid_0's binary_logloss: 0.00484779\tvalid_1's binary_logloss: 0.122665\n",
            "Early stopping, best iteration is:\n",
            "[329]\tvalid_0's binary_logloss: 0.00663683\tvalid_1's binary_logloss: 0.122069\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  40%|####      | 2/5 [00:12<00:12,  4.25s/it]\u001b[A\u001b[A\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  60%|######    | 3/5 [00:12<00:08,  4.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:33,910]\u001b[0m Trial 62 finished with value: 0.12206886823155069 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.11927011248326207.\u001b[0m\n",
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  60%|######    | 3/5 [00:12<00:08,  4.06s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.11166\tvalid_1's binary_logloss: 0.181829\n",
            "[200]\tvalid_0's binary_logloss: 0.0462916\tvalid_1's binary_logloss: 0.138447\n",
            "[300]\tvalid_0's binary_logloss: 0.023944\tvalid_1's binary_logloss: 0.124779\n",
            "[400]\tvalid_0's binary_logloss: 0.0144954\tvalid_1's binary_logloss: 0.12155\n",
            "[500]\tvalid_0's binary_logloss: 0.00970253\tvalid_1's binary_logloss: 0.120066\n",
            "[600]\tvalid_0's binary_logloss: 0.00708026\tvalid_1's binary_logloss: 0.118876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  60%|######    | 3/5 [00:15<00:08,  4.06s/it]\u001b[A\u001b[A\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  80%|########  | 4/5 [00:15<00:04,  4.01s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:37,801]\u001b[0m Trial 63 finished with value: 0.1185221084207312 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.1185221084207312.\u001b[0m\n",
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  80%|########  | 4/5 [00:15<00:04,  4.01s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[583]\tvalid_0's binary_logloss: 0.00743331\tvalid_1's binary_logloss: 0.118522\n",
            "Training until validation scores don't improve for 100 rounds\n",
            "[100]\tvalid_0's binary_logloss: 0.0413871\tvalid_1's binary_logloss: 0.148478\n",
            "[200]\tvalid_0's binary_logloss: 0.0122639\tvalid_1's binary_logloss: 0.120436\n",
            "[300]\tvalid_0's binary_logloss: 0.0059025\tvalid_1's binary_logloss: 0.116758\n",
            "[400]\tvalid_0's binary_logloss: 0.00367045\tvalid_1's binary_logloss: 0.11621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484:  80%|########  | 4/5 [00:21<00:04,  4.01s/it]\u001b[A\u001b[A\n",
            "\n",
            "min_data_in_leaf, val_score: 0.111484: 100%|##########| 5/5 [00:21<00:00,  4.36s/it]\u001b[A\u001b[A\u001b[32m[I 2021-07-08 14:41:42,996]\u001b[0m Trial 64 finished with value: 0.11565889903894985 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.11565889903894985.\u001b[0m\n",
            "min_data_in_leaf, val_score: 0.111484: 100%|##########| 5/5 [00:21<00:00,  4.22s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Early stopping, best iteration is:\n",
            "[345]\tvalid_0's binary_logloss: 0.00466623\tvalid_1's binary_logloss: 0.115659\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ze_zhgHzXR3t"
      },
      "source": [
        "#### Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oumLiq3S_HSZ",
        "outputId": "9327ccc1-e0b4-4c5a-d9c5-bade09870081"
      },
      "source": [
        "# 3.2 This predicts probabilities:\n",
        "model.predict(\n",
        "                val_x,    # Note that it is not lightgbm dataset\n",
        "                num_iteration = model.best_iteration\n",
        "             )"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.89867300e-03, 4.52102587e-03, 5.34720865e-03, ...,\n",
              "       9.97818112e-01, 6.13891045e-04, 9.98700961e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNA2LOZEzzPs",
        "outputId": "0abf64d2-9956-41fb-c8a1-536824482981"
      },
      "source": [
        "### Model is ready\n",
        "# 4.0 Make prediction\n",
        "#     np.rint: Round elements of the array to the nearest integer. \n",
        "#     For values exactly halfway between rounded decimal values,\n",
        "#     NumPy rounds to the nearest even value. Thus 1.5 and 2.5 \n",
        "#     round to 2.0, -0.5 and 0.5 round to 0.0, etc.\n",
        "\n",
        "prediction = np.rint(\n",
        "                     model.predict(\n",
        "                                    val_x,    # Note that it is not lightgbm dataset\n",
        "                                    num_iteration = model.best_iteration\n",
        "                                    )\n",
        "                    )\n",
        "\n",
        "# 4.0.1\n",
        "prediction"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 1., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzgEAhVMXXMt"
      },
      "source": [
        "#### Get model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7gnxL1_vKww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a926b31-7c0a-4c57-844d-38307a90d295"
      },
      "source": [
        "# 4.1 Determine accuracy\n",
        "accuracy = accuracy_score(val_y, prediction)\n",
        "\n",
        "# 4.2 Get best params\n",
        "best_params = model.params\n",
        "print(\"\\nbest_params: \" ,best_params) \n",
        "print(\"\\n===============\")\n",
        "print(\"\\nAccuracy: \", accuracy)\n",
        "print(\"\\n===============\")\n",
        "\n",
        "# 4.3\n",
        "for key, value in best_params.items():\n",
        "    print(\"\\n    {}: {}\".format(key, value))\n",
        "\n",
        "######################\n"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "best_params:  {'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'boosting_type': 'gbdt', 'feature_pre_filter': False, 'lambda_l1': 0.0009868172868937799, 'lambda_l2': 2.4843451284052835, 'num_leaves': 79, 'feature_fraction': 0.92, 'bagging_fraction': 0.5522670384439083, 'bagging_freq': 3, 'min_child_samples': 20, 'num_iterations': 1000, 'early_stopping_round': 100, 'categorical_column': [0, 1]}\n",
            "\n",
            "===============\n",
            "\n",
            "Accuracy:  0.9608\n",
            "\n",
            "===============\n",
            "\n",
            "    objective: binary\n",
            "\n",
            "    metric: binary_logloss\n",
            "\n",
            "    verbosity: -1\n",
            "\n",
            "    boosting_type: gbdt\n",
            "\n",
            "    feature_pre_filter: False\n",
            "\n",
            "    lambda_l1: 0.0009868172868937799\n",
            "\n",
            "    lambda_l2: 2.4843451284052835\n",
            "\n",
            "    num_leaves: 79\n",
            "\n",
            "    feature_fraction: 0.92\n",
            "\n",
            "    bagging_fraction: 0.5522670384439083\n",
            "\n",
            "    bagging_freq: 3\n",
            "\n",
            "    min_child_samples: 20\n",
            "\n",
            "    num_iterations: 1000\n",
            "\n",
            "    early_stopping_round: 100\n",
            "\n",
            "    categorical_column: [0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEx5vVfk2fC7"
      },
      "source": [
        "## Bayesian optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4oP7XLS6OLD"
      },
      "source": [
        "#### Model Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riHBaNDk2kQL"
      },
      "source": [
        "# 5.0. Define classifier object:\n",
        "\n",
        "model_lgb = lgb.LGBMRegressor(                # Regressor will also perform classification\n",
        "                                objective='binary',\n",
        "                                metric='auc', # This output must match with what\n",
        "                                          #  we specify as input to Bayesian model\n",
        "                                n_jobs=2,\n",
        "                                verbose=0,\n",
        "                                #baggeng_freq=1,\n",
        "                                #bagging_fraction =0.8,\n",
        "                              )"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwuxr2GIEGXv"
      },
      "source": [
        "# 5.1 Our pipeline\n",
        "pipe = Pipeline(\n",
        "                  [\n",
        "                    (\"ss\", StandardScaler()),\n",
        "                    (\"pca\", PCA(n_components = 0.95)),\n",
        "                    (\"lgb\", model_lgb)\n",
        "                  ]\n",
        "                )\n",
        "\n",
        "# 5.1.1\n",
        "pipe.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWdSr0f36KYi"
      },
      "source": [
        "#### Parameter space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBwd-hUU2osN"
      },
      "source": [
        "# 5.1 Parameter search space for selected modeler\n",
        "#      For suggested parameter grid for lightgbm, pl see: \n",
        "#         https://github.com/Microsoft/LightGBM/issues/695\n",
        "#\n",
        "params = {\n",
        "        # The 'boosting' option parameter give lots of errors. \n",
        "        # Do not use it. (Removed 'rf' from it. Avoids errors)\n",
        "        'lgb__boosting'    :   Categorical(['gbdt','dart']),                                                         \n",
        "        'lgb__n_estimators':   Integer(50, 100), # No of boosted trees or iterations to fit (default: 100).\n",
        "\n",
        "        'lgb__num_leaves'  :   Integer(5,45),   # Max tree leaves for base boosters\n",
        "                                           # Create a node only if no of leaves exceed this limit\n",
        "                                           #  and also following condition of 'min_child_samples' is met\n",
        "\n",
        "        'lgb__min_child_samples': Integer(1, 50),  # Create a node only if min data-points at this node\n",
        "                                              #  exceed this limit\n",
        "\n",
        "        'lgb__feature_fraction' : Real(0.1, 0.9),  # Randomly select part of features on each iteration\n",
        "                                              #  for every boosted tree\n",
        "\n",
        "        'lgb__bagging_fraction' : Real(0.8, 1),   # Randomly select part of data without resampling\n",
        "                                             #   for each boosted tree\n",
        "\n",
        "        'lgb__bagging_freq'     : Integer(1,10),  # k means perform bagging at every k iteration\n",
        "\n",
        "        'lgb__max_depth'        : Integer(1, 50), # Max tree depth for base learners, -1 means no limit.\n",
        "\n",
        "        'lgb__learning_rate': Real(0.01, 1.0, 'log-uniform'), # Prob of interval 1 to 10 is same as 10 to 100\n",
        "                                                         # Equal prob of selection from 0.01 to 0.1, 0.1\n",
        "                                                         # to 1\n",
        "                                                         # In a loguniform distributon, log-transformed\n",
        "                                                         # random variable is uniformly distributed\n",
        "\n",
        "        'lgb__reg_lambda': Real(1e-9, 1000, 'log-uniform'),  # L2 regularization term on weights.\n",
        "        'lgb__reg_alpha':  Real(1e-9, 1.0, 'log-uniform'),   #  L1 regularization\n",
        "\n",
        "        'lgb__scale_pos_weight': Real(1, 10),    # default: 1\n",
        "                                            # used only in binary application\n",
        "                                            # How much more importance should be given to binary\n",
        "                                            # weight of labels with positive class\n",
        "\n",
        "        #-----***** Not understood **** -----\n",
        "\n",
        "        'lgb__max_bin': Integer(100, 1000),      # max number of bins that feature\n",
        "                                            #  values will be bucketed in\n",
        "                                            # small number of bins may reduce\n",
        "                                            # training accuracy but may increase\n",
        "                                            # general power (deal with over-fitting)\n",
        "\n",
        "        'lgb__min_child_weight':  Real(1, 10),   # Deals with overfitting\n",
        "\n",
        "        'lgb__subsample_for_bin': Integer(100000, 500000)  #  Number of samples for constructing bins(default: 200000)\n",
        "                                               # setting this to larger value will give better training\n",
        "                                               #  result, but will increase data loading time\n",
        "           }\n",
        "\n"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-2bp6_v6Bek"
      },
      "source": [
        "#### Cross validation strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_PnKV6G6EO0"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "FCCDwa6z2sPj",
        "outputId": "a101ebd9-02bd-4c3a-ca4b-c912f8fc6f76"
      },
      "source": [
        "# 5.2 Cross validation strategy for the modeler\n",
        "#      Perform startified k-fold cross-validation\n",
        "#      There is also RepeatedStratifiedKFold() class\n",
        "#      that will repeat startified k-fold N-number\n",
        "#      of times\n",
        "#      Instantiate cross-vlidation object\n",
        "\"\"\"\n",
        "Examples of Cross-validation strategies:\n",
        "    i)   Leave one out  : Very time consuming\n",
        "    ii)  Leave P out    : For example, leave 2 out\n",
        "    iii) kfold          : k-equal random folds\n",
        "    iv)  StratifiedKFold : kfolds + stratification\n",
        "    v)   ShuffleSplit  => Generate n-numbers of userdefined pairs\n",
        "                          of (train,test). For examples, in each\n",
        "                          (train,test) pair, let number of rows\n",
        "                          of 'test' data be 30% of train data\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "cvStrategy = StratifiedKFold(\n",
        "                             n_splits=3,\n",
        "                             shuffle=True,\n",
        "                             random_state=42\n",
        "                            )"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nExamples of Cross-validation strategies:\\n    i)   Leave one out  : Very time consuming\\n    ii)  Leave P out    : For example, leave 2 out\\n    iii) kfold          : k-equal random folds\\n    iv)  StratifiedKFold : kfolds + stratification\\n    v)   ShuffleSplit  => Generate n-numbers of userdefined pairs\\n                          of (train,test). For examples, in each\\n                          (train,test) pair, let number of rows\\n                          of 'test' data be 30% of train data\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83_tkl2a55gH"
      },
      "source": [
        "#### Bayes tuner object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM_1l4jF2u6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c845d1-3fa4-4b9b-85ea-d4aa04c73aca"
      },
      "source": [
        "# 5.3 Bayesian object instantiation\n",
        "#     For API, refer: https://scikit-optimize.github.io/#skopt.BayesSearchCV\n",
        "#     For example: https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html\n",
        "\n",
        "start = time.time()\n",
        "bayes_cv_tuner = BayesSearchCV(\n",
        "                              estimator = pipe,    # rf, lgb, xgb, nn , pipeline etc--Black box\n",
        "                              search_spaces = params,  # Specify params as required by the estimator\n",
        "                              scoring = 'roc_auc',  # Input to Bayes function\n",
        "                                                    # modeler should return this\n",
        "                                                    # peformence metric\n",
        "                              cv = cvStrategy,      # Optional. Determines the cross-validation splitting strategy.\n",
        "                                                    #           Can be cross-validation generator or an iterable,\n",
        "                                                    #           Possible inputs for cv are: - None, to use the default 3-fold cv,\n",
        "                                                    #           - integer, to specify the number of folds in a (Stratified)KFold,\n",
        "                                                    #           - An object to be used as a cross-validation generator.\n",
        "                              n_jobs = 2,           # Start two parallel threads for processing\n",
        "                              n_iter = 10,        # How many times to look for parameter sets\n",
        "                              verbose = 1,\n",
        "                              refit = True,       #  Refit the best estimator with the entire dataset\n",
        "                              random_state = 42\n",
        "                               )\n",
        "end = time.time()\n",
        "(end-start)/60"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.5192896525065104e-06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8j5B089506S"
      },
      "source": [
        "#### Begin tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSylYoba2y6L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82eceed3-6cac-46ec-aded-4c8e9a377f07"
      },
      "source": [
        "# 5.4 Start learning using Bayes tuner\n",
        "\n",
        "start = time.time()\n",
        "result = bayes_cv_tuner.fit(\n",
        "                            train_x,       # Note that we use normal train data\n",
        "                            train_y,       #  rather than lgb train-data matrix\n",
        "                            #callback=status_print\n",
        "                           )\n",
        "\n",
        "end = time.time()\n",
        "(end - start)/60"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    3.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    7.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    4.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    2.1s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    8.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    3.9s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    1.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    8.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    1.4s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] bagging_fraction is set=0.9674776711106569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9674776711106569\n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8609791252746636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8609791252746636\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9674776711106569, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9674776711106569\n",
            "[LightGBM] [Warning] boosting is set=dart, boosting_type=gbdt will be ignored. Current value: boosting=dart\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8609791252746636, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8609791252746636\n",
            "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001450 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7553601185480754"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd4ly49X5wmS"
      },
      "source": [
        "#### Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylRwPe3-21Op",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344e3b65-82d7-48de-e560-b650fbe2c930"
      },
      "source": [
        "# 6.0 So what are the results?\n",
        "#      Use the following estimator in future\n",
        "#      What parameters the best estimator was using?\n",
        "\n",
        "best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
        "print(best_params)\n",
        "\n",
        "# 6.1 Best auc score for the above estimator\n",
        "\n",
        "print(\"\\n\\nBest score: \", np.round(bayes_cv_tuner.best_score_, 4))\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lgb__bagging_fraction     0.967478\n",
            "lgb__bagging_freq                9\n",
            "lgb__boosting                 dart\n",
            "lgb__feature_fraction     0.860979\n",
            "lgb__learning_rate        0.534879\n",
            "lgb__max_bin                   156\n",
            "lgb__max_depth                   8\n",
            "lgb__min_child_samples          18\n",
            "lgb__min_child_weight      6.72156\n",
            "lgb__n_estimators               98\n",
            "lgb__num_leaves                 30\n",
            "lgb__reg_alpha            0.852405\n",
            "lgb__reg_lambda            1.59034\n",
            "lgb__scale_pos_weight      4.49672\n",
            "lgb__subsample_for_bin      342928\n",
            "dtype: object\n",
            "\n",
            "\n",
            "Best score:  0.9804\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "sxdUqR6k25Jf",
        "outputId": "4ecaa287-bafd-4bfe-c6ca-3484078068c2"
      },
      "source": [
        "# 6.2 Summary of all models developed by Bayes process\n",
        "\n",
        "allModels_summary = pd.DataFrame(bayes_cv_tuner.cv_results_)\n",
        "allModels_summary.shape  # 50 X 26 ; 50 iterations\n",
        "\n",
        "# 6.3\n",
        "allModels_summary.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 26)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_lgb__bagging_fraction</th>\n",
              "      <th>param_lgb__bagging_freq</th>\n",
              "      <th>param_lgb__boosting</th>\n",
              "      <th>param_lgb__feature_fraction</th>\n",
              "      <th>param_lgb__learning_rate</th>\n",
              "      <th>param_lgb__max_bin</th>\n",
              "      <th>param_lgb__max_depth</th>\n",
              "      <th>param_lgb__min_child_samples</th>\n",
              "      <th>param_lgb__min_child_weight</th>\n",
              "      <th>param_lgb__n_estimators</th>\n",
              "      <th>param_lgb__num_leaves</th>\n",
              "      <th>param_lgb__reg_alpha</th>\n",
              "      <th>param_lgb__reg_lambda</th>\n",
              "      <th>param_lgb__scale_pos_weight</th>\n",
              "      <th>param_lgb__subsample_for_bin</th>\n",
              "      <th>params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.972303</td>\n",
              "      <td>0.971574</td>\n",
              "      <td>0.967746</td>\n",
              "      <td>0.970541</td>\n",
              "      <td>0.001999</td>\n",
              "      <td>5</td>\n",
              "      <td>0.780756</td>\n",
              "      <td>0.378145</td>\n",
              "      <td>0.022572</td>\n",
              "      <td>0.006248</td>\n",
              "      <td>0.882021</td>\n",
              "      <td>8</td>\n",
              "      <td>gbdt</td>\n",
              "      <td>0.352640</td>\n",
              "      <td>0.218925</td>\n",
              "      <td>473</td>\n",
              "      <td>18</td>\n",
              "      <td>37</td>\n",
              "      <td>3.740170</td>\n",
              "      <td>82</td>\n",
              "      <td>27</td>\n",
              "      <td>1.385174e-08</td>\n",
              "      <td>1.370904e-07</td>\n",
              "      <td>6.688861</td>\n",
              "      <td>131156</td>\n",
              "      <td>{'lgb__bagging_fraction': 0.8820207917706628, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.981035</td>\n",
              "      <td>0.982340</td>\n",
              "      <td>0.977917</td>\n",
              "      <td>0.980431</td>\n",
              "      <td>0.001856</td>\n",
              "      <td>1</td>\n",
              "      <td>4.624523</td>\n",
              "      <td>2.979596</td>\n",
              "      <td>0.035045</td>\n",
              "      <td>0.010345</td>\n",
              "      <td>0.967478</td>\n",
              "      <td>9</td>\n",
              "      <td>dart</td>\n",
              "      <td>0.860979</td>\n",
              "      <td>0.534879</td>\n",
              "      <td>156</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>6.721562</td>\n",
              "      <td>98</td>\n",
              "      <td>30</td>\n",
              "      <td>8.524050e-01</td>\n",
              "      <td>1.590337e+00</td>\n",
              "      <td>4.496724</td>\n",
              "      <td>342928</td>\n",
              "      <td>{'lgb__bagging_fraction': 0.9674776711106569, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.952665</td>\n",
              "      <td>0.946298</td>\n",
              "      <td>0.945274</td>\n",
              "      <td>0.948079</td>\n",
              "      <td>0.003270</td>\n",
              "      <td>8</td>\n",
              "      <td>2.580701</td>\n",
              "      <td>1.478836</td>\n",
              "      <td>0.025732</td>\n",
              "      <td>0.007254</td>\n",
              "      <td>0.888967</td>\n",
              "      <td>9</td>\n",
              "      <td>dart</td>\n",
              "      <td>0.446666</td>\n",
              "      <td>0.023763</td>\n",
              "      <td>508</td>\n",
              "      <td>9</td>\n",
              "      <td>38</td>\n",
              "      <td>6.016064</td>\n",
              "      <td>99</td>\n",
              "      <td>33</td>\n",
              "      <td>2.711809e-06</td>\n",
              "      <td>2.367361e-07</td>\n",
              "      <td>5.585960</td>\n",
              "      <td>278139</td>\n",
              "      <td>{'lgb__bagging_fraction': 0.8889665024602303, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.975458</td>\n",
              "      <td>0.971274</td>\n",
              "      <td>0.968668</td>\n",
              "      <td>0.971800</td>\n",
              "      <td>0.002797</td>\n",
              "      <td>4</td>\n",
              "      <td>1.314180</td>\n",
              "      <td>0.777748</td>\n",
              "      <td>0.025220</td>\n",
              "      <td>0.009816</td>\n",
              "      <td>0.962479</td>\n",
              "      <td>3</td>\n",
              "      <td>gbdt</td>\n",
              "      <td>0.742212</td>\n",
              "      <td>0.111200</td>\n",
              "      <td>186</td>\n",
              "      <td>38</td>\n",
              "      <td>44</td>\n",
              "      <td>9.207360</td>\n",
              "      <td>69</td>\n",
              "      <td>19</td>\n",
              "      <td>3.449623e-02</td>\n",
              "      <td>2.114410e-02</td>\n",
              "      <td>1.236578</td>\n",
              "      <td>485880</td>\n",
              "      <td>{'lgb__bagging_fraction': 0.9624791976714727, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.977447</td>\n",
              "      <td>0.979402</td>\n",
              "      <td>0.973138</td>\n",
              "      <td>0.976662</td>\n",
              "      <td>0.002617</td>\n",
              "      <td>2</td>\n",
              "      <td>5.777725</td>\n",
              "      <td>3.849617</td>\n",
              "      <td>0.026366</td>\n",
              "      <td>0.009205</td>\n",
              "      <td>0.959911</td>\n",
              "      <td>5</td>\n",
              "      <td>gbdt</td>\n",
              "      <td>0.672571</td>\n",
              "      <td>0.642250</td>\n",
              "      <td>745</td>\n",
              "      <td>22</td>\n",
              "      <td>33</td>\n",
              "      <td>4.177755</td>\n",
              "      <td>83</td>\n",
              "      <td>26</td>\n",
              "      <td>8.740059e-02</td>\n",
              "      <td>1.165902e-06</td>\n",
              "      <td>3.383559</td>\n",
              "      <td>207155</td>\n",
              "      <td>{'lgb__bagging_fraction': 0.9599106883214347, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   split0_test_score  ...                                             params\n",
              "0           0.972303  ...  {'lgb__bagging_fraction': 0.8820207917706628, ...\n",
              "1           0.981035  ...  {'lgb__bagging_fraction': 0.9674776711106569, ...\n",
              "2           0.952665  ...  {'lgb__bagging_fraction': 0.8889665024602303, ...\n",
              "3           0.975458  ...  {'lgb__bagging_fraction': 0.9624791976714727, ...\n",
              "4           0.977447  ...  {'lgb__bagging_fraction': 0.9599106883214347, ...\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dpfv7-b8X9w"
      },
      "source": [
        "####### I am done #############"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}