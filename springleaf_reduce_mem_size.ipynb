{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "springleaf_reduce_mem_size.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1F8LbBoN7dcDLeCMdDHYOMOx2i2uUk7mx",
      "authorship_tag": "ABX9TyNZ0k2aUdZhbtPAcSIsypTx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/classification/blob/main/springleaf_reduce_mem_size.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6JITZZEeHmc"
      },
      "source": [
        "# Last amended: 20th August, 2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ_5U31BZ2EB"
      },
      "source": [
        "# Springleaf problem--Reducing dataset size\n",
        "This notebook shows:<br>\n",
        "a) How to reduce memory size of a DataFrame (para #3.0) <br>\n",
        "b. How to derive correct dtype information of each column in a dictionary format (para #3.0)<br>\n",
        "c. How to use this dictionary to read the large dataset in correct dtype format (para #6.0)<br>\n",
        "d. How to store the dtype-dictioary for use subsequently (paras #7.0 to #9.0)<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU7eWoWeXVlp"
      },
      "source": [
        "# 1.0 Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLfhDb9dhKap"
      },
      "source": [
        "# 1.1 Display multiple commands output from a cell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-5L_EwtaBBG"
      },
      "source": [
        "### Mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt-cUDvyYRhp",
        "outputId": "b1e8340a-7660-4553-f9c8-710a6ef40a05"
      },
      "source": [
        "# 2.0\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq8qutv1aEMu"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVX2_U5jXVUc"
      },
      "source": [
        "# 2.1 Read train.csv.zip file from gdrive\n",
        "#     Takes 2 minutes\n",
        "\n",
        "%%time\n",
        "filepath = \"/gdrive/MyDrive/Colab_data_files/springleaf_marketing/train.csv.zip\"\n",
        "df = pd.read_csv(filepath, low_memory = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fAPd-8MXRfC"
      },
      "source": [
        "# 2.2 Memory usage?\n",
        "df.shape\n",
        "print()\n",
        "df.memory_usage().sum()  # 22,470,14160 bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVxewcSXaHbo"
      },
      "source": [
        "### Get column names where nulls do not exist\n",
        "Else, null columns must first be filled in before memory can be reduced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QDn6-RHZJ5-"
      },
      "source": [
        "# 2.3 Which columns contain nulls\n",
        "cols = df.isnull().sum()[df.isnull().sum() > 0]\n",
        "print(cols.index.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE_14CtEaQSO"
      },
      "source": [
        "# 2.4 Array of column names that are NOT null\n",
        "df.isnull().sum()[df.isnull().sum() > 0].index.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQEYVJLTbW4d"
      },
      "source": [
        "# 2.5 List of column that have no nulls\n",
        "cols = list(df.isnull().sum()[df.isnull().sum() <= 0].index.values)\n",
        "print(cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHjJjdgRtKep"
      },
      "source": [
        "The following function has bee taken from Kaggle. It has been modified to return both the dataframe (with reduced memory) as also column types. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozD5W1v6XSiI"
      },
      "source": [
        "# 3.0 Last amended: 20th August, 2021\n",
        "# Myfolder: C:\\Users\\Administrator\\OneDrive\\Documents\\useful_code & utilities\n",
        "# Ref: https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
        "\n",
        "# 3.1 Will store column types\n",
        "coltypes = {}\n",
        "\n",
        "# 3.2 Function to reduce memory\n",
        "#     DataFrame must not have NULLs\n",
        "\n",
        "def reduce_mem_usage(df):\n",
        "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
        "        to reduce memory usage. \n",
        "        If NaN exist fill them up first\t\t\n",
        "    \"\"\"\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                    coltypes[col] = np.int8\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                    coltypes[col] = np.int16\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                    coltypes[col] = np.int32\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64) \n",
        "                    coltypes[col] = np.int64  \n",
        "            else:\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                    coltypes[col] = np.float16\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                    coltypes[col] = np.float32\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "                    coltypes[col] = np.float64\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "            coltypes[col] = 'category'\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df,coltypes"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N8XU7JVbllo",
        "outputId": "4141ba14-1447-49fb-9f9f-09cb8156f517"
      },
      "source": [
        "# 4.0 Reduce memory usage\n",
        "#      For not null columns\n",
        "#       7 mins\n",
        "\n",
        "%%time\n",
        "\n",
        "# 4.1 Consider only not null columns\n",
        "data = df[cols].copy()\n",
        "\n",
        "# 4.2 Apply reduce_mem_usage()\n",
        "data,feat_types = reduce_mem_usage(data)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 1561.21 MB\n",
            "Memory usage after optimization is: 429.91 MB\n",
            "Decreased by 72.5%\n",
            "CPU times: user 7min 8s, sys: 44.8 s, total: 7min 53s\n",
            "Wall time: 7min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFREpoGZbsAu"
      },
      "source": [
        "# 4.3\n",
        "data.shape\n",
        "print()\n",
        "\n",
        "# 4.3.1\n",
        "data.memory_usage().sum()   # 450797648\n",
        "print()\n",
        "\n",
        "# 4.3.2\n",
        "print(\"\\nColumn wise Data types:\")\n",
        "print(feat_types)\n",
        "\n",
        "print(\"\\nHow many columns?\")\n",
        "len(feat_types)    # 1409"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_T1VTF1jcvF"
      },
      "source": [
        "%%time\n",
        "\n",
        "# 5.0 Now modify the original dataframe\n",
        "df[cols] = data   # 7 minutes\n",
        "\n",
        "# 5.1 And delete data\n",
        "del data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7aaP8HbnscP"
      },
      "source": [
        "# 5.2\n",
        "df.shape\n",
        "print()\n",
        "df.memory_usage().sum()  # 1060767848"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr0t0DRE8u9W"
      },
      "source": [
        "feat_types"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTCN4Qharu2n"
      },
      "source": [
        "# 6.0 Next time:\n",
        "# 6.0 Read dataset again but specify\n",
        "#     column dtypes. \n",
        "#     Columns whose dtypes have not been specified\n",
        "#     will be read by default dtype of 64 bit\n",
        "\n",
        "%%time\n",
        "\n",
        "dfx = pd.read_csv(filepath,\n",
        "                  dtype = feat_types\n",
        "                  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrvM_7jjw63J"
      },
      "source": [
        "# 6.1 Checks:\n",
        "dfx.memory_usage().sum()\n",
        "print()\n",
        "dfx.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCniJ4O22X79"
      },
      "source": [
        "### You can save your dictioary to gdrive as follows:\n",
        "Generally 'pickle' package is used to store python objects. We will use pickle here also.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDHdnP1m-Rcm"
      },
      "source": [
        "# 7.0 Define functions to save dictionary to a file\n",
        "#      and read from it\n",
        "# Ref StackOverflow\n",
        "#       https://stackoverflow.com/a/19201448/3282777\n",
        "\n",
        "# 7.1 Import needed package\n",
        "import pickle\n",
        "\n",
        "# 7.2 Function to save the dictionary (ie obj)\n",
        "def save_obj(obj, folder, fileToSaveTo ):\n",
        "    with open(folder+'/'+ fileToSaveTo + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# 7.3 Read the dictionary ie stored pickle file\n",
        "def load_obj(folder, pickle_file ):\n",
        "    with open(folder +'/' + pickle_file + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gszj8do-WujN"
      },
      "source": [
        "# 8.0 First create a blank file where we want\n",
        "#      our dictionary containing dtype information\n",
        "#        to be stored\n",
        "\n",
        "# 8.1 The folder and filename\n",
        "folder = \"/gdrive/MyDrive/Colab_data_files/springleaf_marketing\"\n",
        "fileToSaveTo = \"myfile\"\n",
        "\n",
        "# 8.2 Make the folder current folder\n",
        "os.chdir(folder)\n",
        "\n",
        "# 8.3 Create a file of '0 byte' size\n",
        "!touch myfile.pkl"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqm1Hy8GYkoK"
      },
      "source": [
        "# 8.4 Save dictioary to file\n",
        "save_obj(feat_types, folder, fileToSaveTo)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpRKTDlH-h1j"
      },
      "source": [
        "# 9.0 Retireve the dictioary back\n",
        "#     For use in reading dataset\n",
        "load_obj(folder, \"myfile\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbfQ9QsK-7DI"
      },
      "source": [
        "############# I am done ##############"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}