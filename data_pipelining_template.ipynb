{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "1.data pipelining template.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/classification/blob/main/data_pipelining_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDvAPLfo2aS7"
      },
      "source": [
        "# Last amended:  10th July, 2020\n",
        "# My folder:    /home/ashok/Documents/5.decisiontree\n",
        "# VM: lubuntu_machinelearning_I\n",
        "# Ref Why dummy encoding:\n",
        "#        https://www.statisticssolutions.com/dummy-coding-the-how-and-why/\n",
        "\n",
        "# Objectives:\n",
        "#     i)    Read and explore data\n",
        "#    ii)    Deal with missing values \n",
        "#   iii)    OneHotEncode categorical features\n",
        "#   iv)     Use Pipeline and ColumnTransformer \n",
        "#            for data transformation\n",
        "#    v)     Pipeline for modeling\n",
        "#    vi)    Nested pipes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZwZ335C2aTB"
      },
      "source": [
        "# 1.0 Reset memory\n",
        "#%reset -f\n",
        "# 1.1 Call libraries\n",
        "\n",
        "## Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1.2 for data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "## Transformers:\n",
        "# 1.3 Class for imputing missing values\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# 1.4 One hot encode categorical data--Convert to dummy\n",
        "from sklearn.preprocessing import OneHotEncoder as onehot\n",
        "\n",
        "# 1.5 Scale numeric data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1.6 Label encode target column\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "## Composite Transformers\n",
        "# 1.7 Class for applying multiple data transformation jobs\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# 1.8 Pipeline class\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# 1.9 Estimator\n",
        "# Ref: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "# User guide: https://scikit-learn.org/stable/modules/tree.html\n",
        "from sklearn.tree import DecisionTreeClassifier "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVR_x1sr2aTC"
      },
      "source": [
        "# 1.10 Display outputs of all commands from a cell--not just of the last command\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UecQ2sRu2aTD"
      },
      "source": [
        "# 2.0 Import warnings module\n",
        "import warnings\n",
        "# 2.1 Do not print warnings on screen\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "CbM3cNrf2aTE",
        "outputId": "c3aba56c-eb8e-4a37-819b-71f95106ab59"
      },
      "source": [
        "# 3.0 Create a toy dataset with six columns\n",
        "#     Every column has at least one NaN except column: 'creditability'\n",
        "#     'creditability' is our target column so no NaN\n",
        "df = pd.DataFrame({\n",
        "                    'creditability' : ['yes','yes','yes','yes','yes','yes','no','no','no','no','no','no','no','no'], # Target column\n",
        "                    'acc_balance'   : [1,2,1,np.nan,1,2,1,2,1,2,2,np.nan,np.nan,np.nan],\n",
        "                    'house_owned'   : ['big','small',np.nan,'small','big',np.nan,np.nan,'big','small','big','big','small',np.nan,'small'],\n",
        "                    'age'           : [21,45,np.nan,40,34,89,23,65,87,np.nan,90,np.nan,60,np.nan],\n",
        "                    'income'        : [np.nan,7.8,3.4,5.5,2.1,8.9,3.9,np.nan,6.9,9.0,np.nan,8.0,8.5,np.nan],  \n",
        "                    'credit_amount' : [1011,np.nan,3211,np.nan,1000,2323,1010,1500,1300,1782,1212,np.nan,1232,np.nan]\n",
        "                  }\n",
        "               )\n",
        "\n",
        "df    # (14,6)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creditability</th>\n",
              "      <th>acc_balance</th>\n",
              "      <th>house_owned</th>\n",
              "      <th>age</th>\n",
              "      <th>income</th>\n",
              "      <th>credit_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>big</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1011.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>small</td>\n",
              "      <td>45.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3211.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>big</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>2323.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1010.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>65.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>small</td>\n",
              "      <td>87.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1782.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>90.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1212.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>1232.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   creditability  acc_balance house_owned   age  income  credit_amount\n",
              "0            yes          1.0         big  21.0     NaN         1011.0\n",
              "1            yes          2.0       small  45.0     7.8            NaN\n",
              "2            yes          1.0         NaN   NaN     3.4         3211.0\n",
              "3            yes          NaN       small  40.0     5.5            NaN\n",
              "4            yes          1.0         big  34.0     2.1         1000.0\n",
              "5            yes          2.0         NaN  89.0     8.9         2323.0\n",
              "6             no          1.0         NaN  23.0     3.9         1010.0\n",
              "7             no          2.0         big  65.0     NaN         1500.0\n",
              "8             no          1.0       small  87.0     6.9         1300.0\n",
              "9             no          2.0         big   NaN     9.0         1782.0\n",
              "10            no          2.0         big  90.0     NaN         1212.0\n",
              "11            no          NaN       small   NaN     8.0            NaN\n",
              "12            no          NaN         NaN  60.0     8.5         1232.0\n",
              "13            no          NaN       small   NaN     NaN            NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "P5kdn8t12aTE",
        "outputId": "df71262d-c470-405b-c78f-5e3294c56bc2"
      },
      "source": [
        "# 3.1 Engineer some new categorical features from 'age' and 'credit_amount'\n",
        "#     We will have NaN values both in 'age_cat' and 'credit_amount_cat' columns\n",
        "#     (Note: Strictly speaking this method of creating features outside pipeline is \n",
        "#     not recommended as it leaks information about X_test (to be created, see below)\n",
        "#     to X_train. Recommended way is to wrap it up inside sklearn's FunctionTransformer\n",
        "#     and then use wrapped transformer within a processing pipeline. See:\n",
        "#     https://scikit-learn.org/stable/modules/preprocessing.html#custom-transformers)\n",
        "#     Else, use KBinsDiscretizer of sklearn\n",
        "\n",
        "df['age_cat'] = pd.cut(df['age'],               # Equal interval cuts between min and max\n",
        "                       3,                       # Three cuts\n",
        "                       labels=[\"1\",\"2\", \"3\"]    # Label for each cut\n",
        "                       )\n",
        "\n",
        "# 3.1.1\n",
        "df['credit_amount_cat'] = pd.qcut(df['credit_amount'],       # Equal freq cut\n",
        "                                  3,\n",
        "                                  labels=[\"low\",\"medium\", \"high\"])\n",
        "df   # (13,8)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creditability</th>\n",
              "      <th>acc_balance</th>\n",
              "      <th>house_owned</th>\n",
              "      <th>age</th>\n",
              "      <th>income</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>credit_amount_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>big</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>1</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>small</td>\n",
              "      <td>45.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3211.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>big</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>2323.0</td>\n",
              "      <td>3</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1010.0</td>\n",
              "      <td>1</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>65.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>2</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>small</td>\n",
              "      <td>87.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>3</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1782.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>90.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1212.0</td>\n",
              "      <td>3</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>2</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   creditability  acc_balance  ... age_cat  credit_amount_cat\n",
              "0            yes          1.0  ...       1                low\n",
              "1            yes          2.0  ...       2                NaN\n",
              "2            yes          1.0  ...     NaN               high\n",
              "3            yes          NaN  ...       1                NaN\n",
              "4            yes          1.0  ...       1                low\n",
              "5            yes          2.0  ...       3               high\n",
              "6             no          1.0  ...       1                low\n",
              "7             no          2.0  ...       2             medium\n",
              "8             no          1.0  ...       3             medium\n",
              "9             no          2.0  ...     NaN               high\n",
              "10            no          2.0  ...       3                low\n",
              "11            no          NaN  ...     NaN                NaN\n",
              "12            no          NaN  ...       2             medium\n",
              "13            no          NaN  ...     NaN                NaN\n",
              "\n",
              "[14 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "Ry93GzGl2aTF",
        "outputId": "326d2aea-5e5f-4438-87ef-4ae1709b6fef"
      },
      "source": [
        "# 3.2 Randomly shuffle data as values \n",
        "#     in 'credibility' column have an order\n",
        "df = df.sample(frac = 1) \n",
        "df    # (13,8)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>creditability</th>\n",
              "      <th>acc_balance</th>\n",
              "      <th>house_owned</th>\n",
              "      <th>age</th>\n",
              "      <th>income</th>\n",
              "      <th>credit_amount</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>credit_amount_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>big</td>\n",
              "      <td>34.0</td>\n",
              "      <td>2.1</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>90.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1212.0</td>\n",
              "      <td>3</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>small</td>\n",
              "      <td>87.0</td>\n",
              "      <td>6.9</td>\n",
              "      <td>1300.0</td>\n",
              "      <td>3</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>65.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>2</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>no</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>23.0</td>\n",
              "      <td>3.9</td>\n",
              "      <td>1010.0</td>\n",
              "      <td>1</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>small</td>\n",
              "      <td>45.0</td>\n",
              "      <td>7.8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.4</td>\n",
              "      <td>3211.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>small</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>big</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1782.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>yes</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>89.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>2323.0</td>\n",
              "      <td>3</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>no</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>60.0</td>\n",
              "      <td>8.5</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>2</td>\n",
              "      <td>medium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yes</td>\n",
              "      <td>1.0</td>\n",
              "      <td>big</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1011.0</td>\n",
              "      <td>1</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   creditability  acc_balance  ... age_cat  credit_amount_cat\n",
              "4            yes          1.0  ...       1                low\n",
              "10            no          2.0  ...       3                low\n",
              "3            yes          NaN  ...       1                NaN\n",
              "8             no          1.0  ...       3             medium\n",
              "7             no          2.0  ...       2             medium\n",
              "6             no          1.0  ...       1                low\n",
              "1            yes          2.0  ...       2                NaN\n",
              "13            no          NaN  ...     NaN                NaN\n",
              "2            yes          1.0  ...     NaN               high\n",
              "11            no          NaN  ...     NaN                NaN\n",
              "9             no          2.0  ...     NaN               high\n",
              "5            yes          2.0  ...       3               high\n",
              "12            no          NaN  ...       2             medium\n",
              "0            yes          1.0  ...       1                low\n",
              "\n",
              "[14 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdzkFAaw2aTF"
      },
      "source": [
        "### Data splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IK22CYOL2aTG",
        "outputId": "28cc8cca-fe45-4c11-f4f1-8b3e159e1950"
      },
      "source": [
        "# 3.3    Popout target\n",
        "#        to separate predictors and target\n",
        "\n",
        "y = df.pop('creditability')\n",
        "y[:3]      # Pandas Series\n",
        "\n",
        "# 3.4   Create an alias of predictors dataset \n",
        "X = df     # X is another name for df\n",
        "X.shape    # (13,7)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4     yes\n",
              "10     no\n",
              "3     yes\n",
              "Name: creditability, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "Hi7ZJdaT2aTG",
        "outputId": "a899d728-6bdf-4144-96be-0c32ffe0ecdc"
      },
      "source": [
        "# 4.0 Split dataset. We will preprocess X_train and apply that\n",
        "#     processing to X_test later\n",
        "X_train,X_test, y_train, y_test = train_test_split(\n",
        "                                                    X,                   # Data features\n",
        "                                                    y,                   # Target column\n",
        "                                                    test_size = 0.3      # split-ratio\n",
        "                                                    )\n",
        "\n",
        "# 4.1 Note the use of f-string for printing\n",
        "f\"X_train shape: {X_train.shape}\"    # (9,7)\n",
        "print()\n",
        "f\"X_test.shape : {X_test.shape}\"     # (4,7)\n",
        "print()\n",
        "f\"y_train shape: {y_train.shape}\"    # (9,)\n",
        "print()\n",
        "f\"y_test shape : {y_test.shape}\"     # (4,)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_train shape: (9, 7)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'X_test.shape : (5, 7)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'y_train shape: (9,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'y_test shape : (5,)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8T8eCBv2aTH"
      },
      "source": [
        "#### Make copy of data set for two separate ways processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT5JVcnG2aTI"
      },
      "source": [
        "# 4.2   Make a copy of X_train\n",
        "#       and X_test for two separate\n",
        "#       ways of data processing\n",
        "#       without using pipes and with pipes\n",
        "\n",
        "X_train_c = X_train.copy()\n",
        "X_test_c  = X_test.copy()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMG6vGL62aTI"
      },
      "source": [
        "### Separate out categorical and numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "QTPkGJ992aTJ",
        "outputId": "be5d3c3b-413a-41ea-f825-cde006874ddd"
      },
      "source": [
        "### 4.3\n",
        "###    Which columns are categorical\n",
        "###    but disguised as integers\n",
        "\n",
        "# 4.3 How many unique values per column.\n",
        "#     Check every column\n",
        "#     We will assume that if number of unique values\n",
        "#      are 4 or less it is categorical column else numeric\n",
        "\n",
        "f\"Total no of unique values per column are:\" ; print()\n",
        "X_train_c.nunique()        # Total no of unique values in each column\n",
        "\n",
        "# 4.4 If no. of unique values less than 5, it is categorical\n",
        "print(\"\\n------\\n\")\n",
        "f\"True are categorical and False are numerical:\" ; print()\n",
        "X_train_c.nunique() < 5    # All True are categorical\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Total no of unique values per column are:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "acc_balance          2\n",
              "house_owned          2\n",
              "age                  5\n",
              "income               5\n",
              "credit_amount        7\n",
              "age_cat              3\n",
              "credit_amount_cat    3\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "------\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'True are categorical and False are numerical:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "acc_balance           True\n",
              "house_owned           True\n",
              "age                  False\n",
              "income               False\n",
              "credit_amount        False\n",
              "age_cat               True\n",
              "credit_amount_cat     True\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXVNP9iD2aTJ",
        "outputId": "ee5a3482-0813-4cac-85db-3498277e9757"
      },
      "source": [
        "# 4.5 Extract list of cat_cols and num_cols:\n",
        "\n",
        "# 4.6 First note which are cat and which are num\n",
        "dg = (X_train_c.nunique() < 5)  \n",
        "dg    # All True are cat and all False are num\n",
        "\n",
        "# 4.7 Then filter out names from Series index \n",
        "cat_cols = dg[dg==True].index.tolist()\n",
        "num_cols = dg[dg==False].index.tolist()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "acc_balance           True\n",
              "house_owned           True\n",
              "age                  False\n",
              "income               False\n",
              "credit_amount        False\n",
              "age_cat               True\n",
              "credit_amount_cat     True\n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzWdSA5W2aTJ",
        "outputId": "0d04e91b-046e-4d29-ed18-ddb179a3039a"
      },
      "source": [
        "# 4.8 Here are the columns\n",
        "cat_cols    #  4\n",
        "print()\n",
        "num_cols    #  3"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['acc_balance', 'house_owned', 'age_cat', 'credit_amount_cat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'income', 'credit_amount']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG62VK5_2aTK"
      },
      "source": [
        "# 4.9 We will create two subsets of num_cols\n",
        "#      One set we will impute using 'mean' \n",
        "#       and the other using 'median'\n",
        "\n",
        "num_cols_mean   = ['age']\n",
        "num_cols_median = ['income', 'credit_amount']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXHseoUP2aTL"
      },
      "source": [
        "# 4.10 We will create two sets of cat_cols\n",
        "#      One set we will fill with 'most_frequent'\n",
        "#       and the other using a constant value\n",
        "\n",
        "cat_cols_mf       = ['acc_balance', 'house_owned']       # 'most_frequent' fill\n",
        "cat_cols_constant = ['age_cat', 'credit_amount_cat']     # 'constant' fill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MDgY2hp2aTL"
      },
      "source": [
        "# 4.11 So we have four datasets for imputing: These are:\n",
        "X_train[num_cols_mean]              # Num dataset, impute by 'mean'   strategy\n",
        "X_train[num_cols_median]            # Num dataset, impute by 'median' strategy\n",
        "X_train[cat_cols_mf]                # Cat dataset, impute by 'most_frequent' strategy\n",
        "X_train[cat_cols_constant]          # Cat dataset, impute by 'constant' strategy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roim7Ncy2aTL"
      },
      "source": [
        "## Part I\n",
        "## Data preprocessing without Pipelining\n",
        "Pre-process each one of the four subsets of data separately. And finally manually concatenate all results to create final dataset. We will henceforth use two terms:<br>\n",
        "<ul>\n",
        "    <li>\n",
        "    transformers: Which transform a dataset. Examples: <i>StandardScaler()</i>, <i>Normalizer()</i>, <i>SimpleImputer()</i>,  <i>OneHotEncoder()</i>, <i>PipeLine()</i>, <i>ColumnTransformer()</i>. Transformers have <i>fit()</i>, <i>transform()</i> and <i>fit_transform()</i> methods. Transformers do not make any predictions and hence there is no <i>predict()</i> method.\n",
        "    </li>\n",
        "    <li>\n",
        "estimators:   Which estimate the pattern in a data. Example: <i>DecisionTreeClassifier</i>, <i>KMeans</i>, <i>GMM</i>.      Estimators have <i>fit()</i> and <i>predict()</i> methods. There is no need for any transformation and hence there is no <i>transform()</i> method.\n",
        "</ul></li>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBxAAgEd2aTL"
      },
      "source": [
        "### Impute missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmU1S9M52aTL"
      },
      "source": [
        "#### Pre-process the two subsets of numerical columns first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoiM_oE52aTM"
      },
      "source": [
        "## 5.1 Impute NaN first in 'num_cols_median'\n",
        "#      Median imputer\n",
        "\n",
        "# 5.1.1 Instantiate SimpleImputer object\n",
        "#        Note the strategy of filling NaN\n",
        "\n",
        "si_median = SimpleImputer(strategy = 'median')\n",
        "\n",
        "# 5.1.2 Next, use 'si_median' object to fit \n",
        "#       and transform at one go and overwrite \n",
        "#       our data-subset\n",
        "\n",
        "X_train_c[num_cols_median] = si_median.fit_transform(X_train_c[num_cols_median])\n",
        "\n",
        "# 5.1.3 Observe result. It should have no NaNs\n",
        "X_train_c[num_cols_median]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-wq0e562aTM"
      },
      "source": [
        "# 5.2 Mean imputer: Same steps as above but\n",
        "#     on different data-subset\n",
        "\n",
        "si_mean = SimpleImputer(strategy = 'mean')\n",
        "X_train_c[num_cols_mean] = si_mean.fit_transform(X_train_c[num_cols_mean])\n",
        "X_train_c[num_cols_mean]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sSMaLRY2aTM"
      },
      "source": [
        "#### Pre-process two subsets of categorical columns, next"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONaqHlgm2aTM"
      },
      "source": [
        "# 5.3 Next impute subset of categorical columns\n",
        "#     with most_frequent\n",
        "\n",
        "si_mf = SimpleImputer(strategy = 'most_frequent')\n",
        "X_train_c[cat_cols_mf] = si_mf.fit_transform(X_train_c[cat_cols_mf])\n",
        "X_train_c[cat_cols_mf]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln__pM9b2aTM"
      },
      "source": [
        "# 5.4 Next impute subset of categorical columns\n",
        "#     with constant value. Our constant value= 'missing'\n",
        "\n",
        "si_constant = SimpleImputer(strategy = 'constant', fill_value = 'missing')\n",
        "X_train_c[cat_cols_constant] = si_constant.fit_transform(X_train_c[cat_cols_constant])\n",
        "X_train_c[cat_cols_constant]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAjtX9xx2aTN"
      },
      "source": [
        "## A Summary\n",
        "# 5.5 So our fitted transformers are:\n",
        "\n",
        "si_median         # To transform num_cols_median\n",
        "si_mean           # To transform num_cols_mean\n",
        "si_mf             # To transform cat_cols_mf\n",
        "si_constant       # To transform cat_cols_constant\n",
        "\n",
        "# 5.6 Our column-colections are:\n",
        "\n",
        "cat_cols          # cat_cols_mf + cat_cols_constant\n",
        "num_cols          # num_cols_mean + num_cols_median\n",
        "\n",
        "cat_cols_mf\n",
        "cat_cols_constant\n",
        "num_cols_mean\n",
        "num_cols_median\n",
        "\n",
        "# 5.7 Our datasets are:\n",
        "\n",
        "X_train[:2],X_test[:2],y_train[:2],y_test[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE21s8EK2aTN"
      },
      "source": [
        "### One hot encoding all categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mb1_kmE2aTN"
      },
      "source": [
        "# 6.0 What does OneHotEncoder do?\n",
        "#     Demo with 'sparse = False'\n",
        "\n",
        "# 6.1 Instantiate onehot class\n",
        "#     through 'ohe' object\n",
        "\n",
        "ohe = onehot(sparse = False)\n",
        "\n",
        "# 6.2 Let 'ohe' learn relevant data\n",
        "#     properties. Our demo data is: 4 X 2\n",
        "\n",
        "ohe.fit(\n",
        "         [                            # A list of lists\n",
        "            ['big'   , 'yes' ],\n",
        "            ['small' , 'no'  ],\n",
        "            ['medium', 'yes' ],\n",
        "            ['big'   , 'no'  ]\n",
        "         ]\n",
        "       )\n",
        "\n",
        "# 6.3 Use 'ohe' to transform demo data\n",
        "#     to dummy values\n",
        "\n",
        "ohe.transform([['big', 'yes'], ['small', 'no'], ['medium', 'yes'],['big','no']])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSQeYXmQ2aTN"
      },
      "source": [
        "# 6.4 In future use 'ohe' to tansform any data with such levels.\n",
        "#     For example:\n",
        "\n",
        "ohe.transform(\n",
        "               [\n",
        "                   ['small'  , 'yes'],\n",
        "                   ['medium' , 'no' ]\n",
        "               ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFDkfgvo2aTN"
      },
      "source": [
        "# 6.5 What does OneHotEncoder do?\n",
        "#    In one line, it transforms dense data to dummy values (1,0)\n",
        "#     Demo with 'sparse = True' -- Output is stored in a special compressed format\n",
        "#     See here dense matrix to sparse matrix conversion example:\n",
        "#     http://www.btechsmartclass.com/data_structures/ds_images/Triplet_Representation_of_Sparse_Matrix.png\n",
        "#     https://www.researchgate.net/publication/328995968/figure/fig4/AS:693582436528129@1542374347304/Illustration-of-the-sparse-matrix-format-A-Example-matrix-of-size-8-8-with-5.png\n",
        "\n",
        "# 6.5.1\n",
        "\n",
        "ohe = onehot(sparse = True)\n",
        "\n",
        "\n",
        "# 6.5.2\n",
        "sp = ohe.fit_transform([['big', 'yes'], ['small', 'no'], ['medium', 'yes'],['big','no']])\n",
        "\n",
        "# 6.5.3\n",
        "sp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_II3Kjv2aTN"
      },
      "source": [
        "# 6.5.4  Transform sparse to dense form\n",
        "sp.toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oz67E6q2aTN"
      },
      "source": [
        "# 6.6 One Hot Encode all categorical columns, cat_cols \n",
        "#     Note, by now all NaNs have been filled\n",
        "\n",
        "ohe = onehot(sparse = False)\n",
        "ohe.fit_transform(X_train_c[cat_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbxE4yXZ2aTN"
      },
      "source": [
        "### Standard scaling all numeric columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIj1QB7T2aTO"
      },
      "source": [
        "# 6.7 Scale all numeric variables in the same manner\n",
        "#     Note, by now all NaNs have been dealth with\n",
        "ss = StandardScaler()\n",
        "ss.fit_transform(X_train_c[num_cols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSrunwTQ2aTO"
      },
      "source": [
        "#### Concatenate pre-processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLAvy-3M2aTO"
      },
      "source": [
        "# 7.0 So complete dataset is:\n",
        "a = ohe.transform(X_train_c[cat_cols])\n",
        "b = ss.transform(X_train_c[num_cols])\n",
        "\n",
        "# 7.1 Horizontally concatenate now\n",
        "Xtrain = np.hstack([a,b]) # It is not X_train\n",
        "Xtrain.shape # (8,14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfIsB1cO2aTO"
      },
      "source": [
        "### Label encoding target\n",
        "Code text values in target column to digits. Our <i>y_train</i> (<i>'Creditability'</i> column) has values 'yes', 'no'..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWK2E7Jy2aTO"
      },
      "source": [
        "# 8.0 Label encode target feature\n",
        "# 8.0.1 Our target\n",
        "f\"Unencoded target column is:\"\n",
        "y_train\n",
        "\n",
        "# 8.0.2 Encode now\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train)\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "\n",
        "# 8.0.3 Just print transformed y_train\n",
        "f\"Encoded y_train is: {y_train}\"   # Encoded y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmR7brMg2aTO"
      },
      "source": [
        "### Decision tree Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fNKfL-j2aTP"
      },
      "source": [
        "# 9.0 Train model using Xtrain\n",
        "from sklearn.tree import DecisionTreeClassifier \n",
        "\n",
        "# 9.1 Instantiate DecisionTreeClassifier class\n",
        "\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# 9.2 Use the classifier object to train \n",
        "#     on our data\n",
        "\n",
        "dt.fit(Xtrain,y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqDxXWBd2aTP"
      },
      "source": [
        "## Transform X_test_c\n",
        "Before making predictions, we need to tranform columns of <i>X_test_c</i> in the same manner we did to X_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az08pKAm2aTP"
      },
      "source": [
        "# 9.3 We now want to predict values for X_test_c\n",
        "\n",
        "# 9.4 First, transform X_test_c in the same manner as we did for X_train\n",
        "#      But this time, there will be no 'fit()'. We will use\n",
        "#       already fitted objects for transformations.\n",
        "\n",
        "#     NOTE: If you have find the error of there being new levels in Xtest,\n",
        "#           execute all code quickly from #4.0 onwards.\n",
        "\n",
        "X_test_c[num_cols_median]  = si_median.transform(X_test_c[num_cols_median])\n",
        "X_test_c[num_cols_mean]    = si_mean.transform(X_test_c[num_cols_mean])\n",
        "X_test_c[cat_cols_constant]= si_constant.transform(X_test_c[cat_cols_constant])\n",
        "X_test_c[cat_cols_mf]      = si_mf.transform(X_test_c[cat_cols_mf]) \n",
        "a                          = ohe.transform(X_test_c[cat_cols])\n",
        "b                          = ss.transform(X_test_c[num_cols])\n",
        "Xtest = np.hstack([a,b])   # Final transformed X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDtlibwo2aTP"
      },
      "source": [
        "# 9.5 Also label encode, y_test\n",
        "#     Using earlier fitted 'le' object\n",
        "f\"Values in y_test are:\"\n",
        "y_test\n",
        "\n",
        "y_test = le.transform(y_test)\n",
        "f\"Transformed y_test is: {y_test}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RldJDcRI2aTP"
      },
      "source": [
        "# 9.6 Make prediction for Xtest\n",
        "dt.predict(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4Cixrp2aTQ"
      },
      "source": [
        "## Part II\n",
        "## Data preprocessing with Pipelining\n",
        "Pre-process each one of the four subsets of data though a pipe and also perform modeling in pipe. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hACa7GuE2aTQ"
      },
      "source": [
        "# 10.0 Create pipes for all transformations\n",
        "# Ref: https://scikit-learn.org/stable/modules/compose.html#pipeline\n",
        "\n",
        "#     ColumnTransformer: Applies specified transformations parallely to each data-subset\n",
        "#     Pipeline         :  Applies transformation sequentially through transformers. \n",
        "#                         Input to pipe is one data-subset. Output of one transformer\n",
        "#                         is fed to another.\n",
        "\n",
        "#     Big picture\n",
        "#     i)   top_pipeline = Pipeline(ColumnTranformer, Estimator)\n",
        "#     ii)  ColumnTransformer([(pipe_mean, cols_mean),(pipe_median, cols_median),\n",
        "#                             (pipe_mf,   cols_mf),  (pipe_constant,cols_const])\n",
        "#     iii) pipe_mean = Pipeline([(imputer), (StandardScaler)]) \n",
        "#      iv) pipe_median=....\n",
        "#\n",
        "#     The pipeline can be used as any other estimator\n",
        "#     and avoids leaking the test set into the train set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPgz-mjo2aTQ"
      },
      "source": [
        "# 10.1 Instantiate Pipeline object for processing numerical data. Impute = mean\n",
        "#     Pipeline as a composite transformer\n",
        "\n",
        "pipe_mean_transformer = Pipeline(\n",
        "                                  [\n",
        "                                    ('si', SimpleImputer(strategy='mean')),\n",
        "                                    ('ss1', StandardScaler())\n",
        "                                  ]\n",
        "                                 )\n",
        "\n",
        "# 10.1.1 Train pipe, just to test if it works\n",
        "pipe_mean_transformer.fit_transform(X_train[num_cols_mean])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vkGgSNn2aTQ"
      },
      "source": [
        "# 10.2 Instantiate Pipeline object for processing numerical data. Impute = median\n",
        "pipe_median_transformer = Pipeline(\n",
        "                                     [\n",
        "                                        ('sm', SimpleImputer(strategy='median')),\n",
        "                                        ('ss2', StandardScaler())\n",
        "                                      ]\n",
        "                                   )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwBHyX7h2aTR"
      },
      "source": [
        "# 10.3 Instantiate Pipeline object for processing cat data. Impute = most_frequent\n",
        "pipe_mf_transfomer = Pipeline(\n",
        "                                [\n",
        "                                  ('mf', SimpleImputer(strategy='most_frequent')),\n",
        "                                  ('ohe', onehot())\n",
        "                                ]\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHRYZDZJ2aTR"
      },
      "source": [
        "# 10.4 Instantiate Pipeline object for processing cat data. Impute = constant\n",
        "sc = SimpleImputer(strategy=\"constant\", fill_value = 'missing')\n",
        "\n",
        "pipe_constant_transformer = Pipeline(\n",
        "                                       [\n",
        "                                          ('cons', sc),\n",
        "                                          ('ohe', onehot())\n",
        "                                        ]\n",
        "                                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xXCW9Pd2aTS"
      },
      "source": [
        "# 10.5 Collecting all pipes in column transformer\n",
        "#     along with column names\n",
        "#                       some-name  transformer     col-names\n",
        "ct_transformer = ColumnTransformer(\n",
        "                                    [\n",
        "                                       ('pm',    pipe_mean_transformer    ,     num_cols_mean   ),\n",
        "                                       ('pme',   pipe_median_transformer  ,    num_cols_median  ),\n",
        "                                       ('pmf',   pipe_mf_transfomer       ,        cat_cols_mf  ),\n",
        "                                       ('pcons', pipe_constant_transformer,   cat_cols_constant )\n",
        "                                    ]\n",
        "                                  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZiHn9qo2aTS"
      },
      "source": [
        "# 10.6 Final pipeline for transformation and modeling\n",
        "#     final_pipe is both a \n",
        "final_pipe_transformer_estimator = Pipeline(\n",
        "                                             [\n",
        "                                                 ('ct', ct_transformer),            # Column transformer object\n",
        "                                                 ('dt', DecisionTreeClassifier()) # Estimator\n",
        "                                             ]\n",
        "                                           )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJSqaIN22aTS"
      },
      "source": [
        "#### Train final_pipe on data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1oS0fD32aTS"
      },
      "source": [
        "# 11.0 Train on data using final_pipe\n",
        "#     We use (X_train, y_train)\n",
        "\n",
        "final_pipe_transformer_estimator.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRrPDH5P2aTS"
      },
      "source": [
        "# 11.1 Make prediction on test data\n",
        "#     Note that there is no need to separately\n",
        "#     transform X_test. Pipes take care of that\n",
        "\n",
        "final_pipe_transformer_estimator.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9G1b6XY2aTT"
      },
      "source": [
        "# 11.2 But what is the actual y_test\n",
        "y_test\n",
        "# le.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u3Gx_Co2aTT"
      },
      "source": [
        "######## That's all folks ##########"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}