{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "performance_metrics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOGXfQe5OLk55YD50/HWQo6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harnalashok/classification/blob/main/performance_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVYbM6aHob8z"
      },
      "source": [
        "\"\"\"\n",
        "Last amended: 17th May, 2020\n",
        "Myfolder: /home/ashok/Documents/10.higgsBoson\n",
        "\n",
        "Create a virtual environment for Conda with essential packages:\n",
        "conda create -n sklearn\n",
        "             -c anaconda\n",
        "             -c conda-forge\n",
        "              python=3.7.6 scikit-learn=0.23.2 pandas ipython numpy spyder imbalanced-learn matplotlib\n",
        "\n",
        "Objectives:\n",
        "              i)  Quick modeling with multiple models\n",
        "             ii)  Learn performance measures: ROC, AUC, confusion_matrix\n",
        "            iii) ROC curve\n",
        "             iv)  To display uniformity of coding in sklearn\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsOQNBBxzHqI"
      },
      "source": [
        "# Import libraries\n",
        "# 1.0\n",
        "# %reset -f\n",
        "\n",
        "# 1.1\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1.2 For generating dataset\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# 1.3 For data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1.4 For data standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1.5 For pipelining\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from imblearn.pipeline import make_pipeline as mp\n",
        "\n",
        "# 1.2 For modeling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from imblearn.over_sampling import SMOTE, ADASYN,BorderlineSMOTE,SVMSMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "\n",
        "# 1.4 For performance measures\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score,precision_score,recall_score\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 1.5 Plotting metrics related graphs\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvqfuySv46j5"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jd17Qg74eh5"
      },
      "source": [
        "# 2.0 Generate arrays of data for classification:\n",
        "#    See examples here: https://towardsdatascience.com/https-medium-com-faizanahemad-generating-synthetic-classification-data-using-scikit-1590c1632922\n",
        "\n",
        "X,y = make_classification(\n",
        "                           n_samples=10000,\n",
        "                           n_features=30,\n",
        "                           n_informative= 26,     # Relevant features\n",
        "                           n_redundant=4,         # Four features are linear combination of some features\n",
        "                           n_repeated =0,         # No duplicate features\n",
        "                           scale = None,          # Multiply features by some random value \n",
        "                           weights=[0.99, 0.01],   # Imbalanced data\n",
        "                           class_sep = 1.5,       # Less it is more difficult class separation\n",
        "                                                  # Value of 0.75 may make hard-decision boundary\n",
        "                           flip_y = 0.1           # Flip randomly 10% of class labels\n",
        "                         )\n",
        "\n",
        "# 2.0.1\n",
        "X.shape        # (10000, 30)\n",
        "print()\n",
        "y\n",
        "print()\n",
        "np.sum(y)/len(y)      # 0.0575, Dataset is highly imbalanced 576/10000\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in7oEG4l6ObN"
      },
      "source": [
        "# 2.1 Split, shuffle and perform stratified sampling:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    shuffle = True,\n",
        "                                                    stratify = y\n",
        "                                                    )\n",
        "\n",
        "# 2.1.1\n",
        "X_train.shape # (7000, 30)\n",
        "X_test.shape  # (3000, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtGPCwK_7QhV"
      },
      "source": [
        "## Understanding PCA\n",
        "Unsupervised learning method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGxpBITa5dD3",
        "outputId": "efe0bf1a-f1f7-4edd-d5e4-892ce371470a"
      },
      "source": [
        "# 2.1 Perform PCA to remove any noisy columns from data:\n",
        "pipe = make_pipeline(\n",
        "                      StandardScaler(),      # This is a must before PCA\n",
        "                      PCA(n_components=0.95)\n",
        "                    )\n",
        "\n",
        "\n",
        "# 2.1.1\n",
        "X_new = pipe.fit_transform(X_train)\n",
        "X_new.shape   # (7000, 20)                   "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "5xW_piIb7or3",
        "outputId": "e8b1ac70-ba6e-4941-8b49-160c06a0892e"
      },
      "source": [
        "std = np.std(X_new, axis = 0)\n",
        "_=plt.plot(range(1,len(std) + 1), std)\n",
        "_=plt.xticks(range(1,len(std)))\n",
        "_=plt.grid()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3gc5bn+8e+j3iVLsuUiyXKXu0HGHSxhehITCIQAhwQScChJSCipJyQcwu8kIaEllCQUkxxACSUBTC+yjXG3ca9ywd3CTbZcVd7fH7t2BFHZXa200u79ua69tLszz8wje3Vr9O67M+acQ0REOr6oUDcgIiLBoUAXEQkTCnQRkTChQBcRCRMKdBGRMBETqh1nZ2e7goKCgGoPHz5McnJywPuO9Pr20IPqVR/J9S2xaNGiPc65zg0udM6F5FZUVOQCVVZWFnCt6ttHD6pXfSTXtwSw0DWSqxpyEREJEwp0EZEwoUAXEQkTzQa6meWZWZmZrTKzlWZ2awPrXG1my8xsuZnNNrPhrdOuiIg0xpdZLjXA7c65xWaWCiwys3edc6vqrbMJmOic229mFwJ/Bka3Qr8iItKIZgPdObcT2Om9f8jMVgM9gFX11pldr2QukBvkPkVEpBnm/DjbopkVADOBIc65g42scwdQ6Jy7voFlU4ApADk5OUWlpaUBtAxVVVWkpKQEVKv69tGD6lUfyfUtUVJSssg5N7LBhY3NZ/z8DUgBFgGXNrFOCbAayGpue4HOQ1+z86Cb8thb7uiJmoDqnQv9HNRQ17eHHlSv+kiubwlaOg/dzGKBl4BnnXMvN7LOMOAJ4GLn3F7/fuf4bvuBI7y9uYbFW/a31i5ERDokX2a5GPAksNo5d38j6+QDLwPXOOfWBbfFzyrqmYkB8zfta83diIh0OL7MchkPXAMsN7Ml3ud+CuQDOOceB+4CsoBHPflPjWtsjKeF0hNjyU+LYt5GBbqISH2+zHKZBVgz61wP/MeboK1lQKcoZmzZz/GaWuJjottqtyIi7VqH/KTogMxojtfUsXxbZahbERFpNzpkoPfv5Dkqn6dxdBGRUzpkoKfGGf1zUhToIiL1dMhABxjdK4tFm/dRU1sX6lZERNqFjhvovTM5fKKWFTsa/MCqiEjE6bCBPqpXJgDzN7XaZ5hERDqUDhvoXVIT6J2drPnoIiJeHTbQwXOUPn/zPmrrfD/BmIhIuOrQgT66dyaHjtWwZpfG0UVEOnag98oC0LCLiAgdPNC7ZySS2ylRJ+oSEaGDBzp4jtLnb9538nzsIiIRKwwCPZN9h0+wvqIq1K2IiIRUxw/03p756DoNgIhEug4f6PmZSXRNS2DeRn3ASEQiW4cPdDPzzEffpHF0EYlsHT7QwTPsUnHoOJv3Hgl1KyIiIRMege49r4uGXUQkkvlykeg8Myszs1VmttLMbm1gHTOzh82s3MyWmdnprdNuw/p0TiE7JU7z0UUkovlykega4Hbn3GIzSwUWmdm7zrlV9da5EOjnvY0GHvN+bRMnx9E100VEIlmzR+jOuZ3OucXe+4eA1UCPz612MfBX5zEXyDCzbkHvtgmjCjLZfuAo2/ZrHF1EIpP5MzPEzAqAmcAQ59zBes9PA37tnJvlffw+8CPn3MLP1U8BpgDk5OQUlZaWBtR0VVUVKSkpn3lu66E6fv7RUW4YGsf4HrF+17d0/x2pvj30oHrVR3J9S5SUlCxyzo1scKFzzqcbkAIsAi5tYNk0YEK9x+8DI5vaXlFRkQtUWVnZfzxXW1vnhv3ybXfnC0sCqm/p/jtSfXvoQfWqj+T6lgAWukZy1adZLmYWC7wEPOuce7mBVbYDefUe53qfazNRUcYZBZl6Y1REIpYvs1wMeBJY7Zy7v5HVXgW+7p3tMgaodM7tDGKfPhnTO5PNe4+w++Cxtt61iEjI+TLLZTxwDbDczJZ4n/spkA/gnHsceAO4CCgHjgDXBb/V5p28zujcjXu5eMTn37cVEQlvzQa687zRac2s44BbgtVUoAZ1SyMlPob5m/Yp0EUk4oTFJ0VPiomOYmRBJ81HF5GIFFaBDp5hl/KKKvZUHQ91KyIibSrsAv3kdUYX6ChdRCJM2AX60B7pJMRGadhFRCJO2AV6XEwURT01ji4ikSfsAh08wy5rdh2k8kh1qFsREWkzYRnoo3pl4hws2KyjdBGJHGEZ6CPyMoiLjmLeJl3wQkQiR1gGekJsNCPyMjSOLiIRJSwDHTzXGV2xvZKq4zWhbkVEpE2Eb6D3yqLOwUKNo4tIhAjbQD+9ZwYxUaZhFxGJGGEb6ElxMQzNTdf50UUkYoRtoINn+uKybQc4eqI21K2IiLS6sA70Mb2yqK51fLxlf6hbERFpdWEd6EUFnYgymKthFxGJAGEd6GkJsQzqnsa8jfqAkYiEP1+uKfqUmVWY2YpGlqeb2WtmttTMVppZSC4/15jRvbL4eOsBjtdoHF1EwpsvR+hTgQuaWH4LsMo5NxwoBn5vZnEtby04RvXK5ERNHUu3Voa6FRGRVtVsoDvnZgJNDUI7INXMDEjxrttuPp45qsBz4WgNu4hIuDPP9Z2bWcmsAJjmnBvSwLJU4FWgEEgFrnDOvd7IdqYAUwBycnKKSktLA2q6qqqKlJQUn9f/71lHSI837jwjMaD6lu6/vdW3hx5Ur/pIrm+JkpKSRc65kQ0udM41ewMKgBWNLLsMeAAwoC+wCUhrbptFRUUuUGVlZX6t//N/LXcDf/6mO1FTG1B9S/ff3urbQw+qV30k17cEsNA1kqvBmOVyHfCyd1/l3kAvDMJ2g2Z0ryyOnKhlxXaNo4tI+ApGoG8BJgGYWQ4wANgYhO0GzRm9OgHovC4iEtZ8mbb4PDAHGGBm28zsW2Z2o5nd6F3lHmCcmS0H3gd+5Jzb03ot+69LagK9OyfrjVERCWsxza3gnLuymeU7gPOC1lErGd0ri2lLd1Bb1/ybwCIiHVFYf1K0vtG9Mjl0vIbVOw+GuhURkVYRMYE+qpd3PrrG0UUkTEVMoHfPSCQvM1Hj6CIStiIm0MEzjj5/8z7qfPgwlYhIRxNhgZ7JgSPV7KhSoItI+ImwQM8CYM0+nXlRRMJPRAV6XmYi3dITWLtfgS4i4SeiAt3MGNUrk7X76k6eh0ZEJGxEVKCDZ9jl4AnHcp3XRUTCTMQF+heGdiMlFn71+modpYtIWIm4QE9PiuUr/eKYv2kfry3bGep2RESCJuICHWBiXgyDu6fx/15fzZET7ebiSiIiLRKRgR5lxt2TB7Pr4DEeKSsPdTsiIkERkYEOMLIgk0tO68FfZm7ik72HQ92OiEiLRWygA/z4wkJio417pq0OdSsiIi0W0YGek5bAdyf1473Vu5m+tiLU7YiItEhEBzrAdeML6JWdzP+8tooTNXWhbkdEJGC+XILuKTOrMLMVTaxTbGZLzGylmc0IboutKz4mmru+OIiNew7z9EebQt2OiEjAfDlCnwpc0NhCM8sAHgUmO+cGA5cHp7W2U1LYhUmFXXj4/fVUHDwW6nZERALSbKA752YCTV3m5yrgZefcFu/6HXIw+udfHER1rePXb64JdSsiIgExXz7+bmYFwDTn3JAGlj0IxAKDgVTgIefcXxvZzhRgCkBOTk5RaWlpQE1XVVWRkpISUG1T9S+uO8G0jdX8bHQC/TpFt/n+26q+PfSgetVHcn1LlJSULHLOjWxwoXOu2RtQAKxoZNkfgblAMpANrAf6N7fNoqIiF6iysrKAa5uqrzpW7Ubf+577wsMzXU1tXZvvv63q20MPqld9JNe3BLDQNZKrwZjlsg142zl32Dm3B5gJDA/CdttccnwMP7mokBXbD/KPhVtD3Y6IiF+CEeivABPMLMbMkoDRQIf9pM7k4d0ZVZDJfW+vpfJIdajbERHxmS/TFp8H5gADzGybmX3LzG40sxsBnHOrgbeAZcB84AnnXKNTHNs7M+MXkwdx4MgJHnhvXajbERHxWUxzKzjnrvRhnfuA+4LSUTswuHs6V43O529zP+Fro/Io7JoW6pZERJoV8Z8Ubczt5w4gNSGGX766UhfCEJEOQYHeiE7Jcdx+3gDmbtzHG8t3hbodEZFmKdCbcNWofAZ2S+Pe11fpQhgi0u4p0JsQHeW5EMaOymM8Pn1DqNsREWmSAr0Zo3plMnl4dx6fuZEte4+Euh0RkUYp0H3w04sGEhNl/Or1VaFuRUSkUQp0H3RNT+CWkr68s2o3M9d9Gup2REQapED30fVn9qJnVhK/fG0lNXWaxigi7Y8C3UenLoTx6WHe/UQzXkSk/VGg+2HSwBxKBnTmlfITfLheQy8i0r4o0P109+QhpMUb1zw5n+ufWcjmPYdD3ZKICKBA91t+VhL3TkjkRxcUMmfDHs59YAb/++ZqDh3TmRlFJLQU6AGIjTJuKu5D2R3FXDyiB3+asZGS383gHwu3Uqc3TEUkRBToLdAlLYHfXT6cV24ZT15mIj98cRkXP/IRiz5p6hKsIiKtQ4EeBMPzMnj5pnE8eMUIKg4d4yuPzeHW0o/ZWXk01K2JSARRoAeJmfHl03rwwe3FfPfsvry5Yhdn/24GD7+/nmPVtaFuT0QigAI9yJLjY7j9vAG8f9tESgo7c/+765j0+xm8vmynzqsuIq1Kgd5K8jKTePTqIp6/YQypCTHc8txirvjzXFbuqAx1ayISpny5puhTZlZhZk1eJ9TMzjCzGjO7LHjtdXxj+2Tx+vfO5N5LhrB+9yG++IdZPL3iOBs/rQp1ayISZnw5Qp8KXNDUCmYWDfwGeCcIPYWd6Cjj6tE9mX5HCdeN68Ws7TWc/fsZfO3Pc3hlyXaO12iMXURazpeLRM80s4JmVvsu8BJwRhB6ClvpSbHc9aVBDIvbxfa4fEoXbOHW0iV0SorlsqJcvjYqnz6dU0Ldpoh0UObLG3XeQJ/mnBvSwLIewHNACfCUd70XG9nOFGAKQE5OTlFpaWlATVdVVZGSEnjwtZf6OudYtbeO6Vur+biilloHAzpFUZwXS1FONHHR1ir7D8Y2VK961Yfm4KukpGSRc25kgwudc83egAJgRSPLXgDGeO9PBS7zZZtFRUUuUGVlZQHXttf63QePukfK1rszf/OB6/mjaW7E3W+7e15b6dbvPhT0/QdjG6pXvepDA1joGsnVZodcfDASKDUzgGzgIjOrcc79KwjbjhhdUhO4ubgvN57Vh9kb9vLc/E+YOnszT8zaxKhemVw9Op/zB3clITY61K2KSDvV4kB3zvU6ed/MpuIZclGYBygqypjQL5sJ/bL59NBxXly0jefne8baM5Ji+crpufShLtRtikg71Gygm9nzQDGQbWbbgF8AsQDOucdbtbsI1zk1npuK+/Dts3ozZ+Nenpu/hb/O2Ux1rePxVWWM65PF2D5ZjOuTTefU+FC3KyIh5ssslyt93Zhz7toWdSMNiooyxvfNZnzfbPZUHefBl2ZSYam8sXwnpQu2AtA/J4VxfbIZ1yeL0b2zSE+MDXHXItLWgjGGLm0oOyWec3rGUlw8kto6x8odlczesJePyvdQumALU2dvJspgSI/0UwE/sqATSXH6rxYJd/op78Cio4xhuRkMy83gxol9OF5Ty5ItB5i9YS+zN+zhiQ838viMDcRGG6fld2JcnyzG981meG5GqFsXkVagQA8j8THRjO7tGXL5wbn9OXy8hgWb9zFnw15mb9jLQ++v58H31pMcF805eVGcMbaG5Hi9BETChX6aw1hyfAzFA7pQPKALAAeOnGDuxn28unQ7ryzfxZzfTeeO8wfwldNziY5q+ENMItJx6GyLESQjKY4LhnTl0auL+NnoBLpneK6y9KU/zGJ2+Z5QtyciLaRAj1D9OkXzz5vH8fCVp1F5tJqrnpjH9c8sYIPOAinSYSnQI5iZMXl4d96/fSI/uqCQuRv3cf4DM/nFKyvYd/hEqNsTET8p0IWE2GhuKu7D9DuLueKMPP429xMm3lfGX2Zu1Kl9RToQBbqckp0Sz72XDOWt759FUc9O3PvGas69fyZvLNfl80Q6AgW6/If+OalMvW4Uz3xzFImx0dz87GIuf3wOS7YeCHVrItIEBbo0amL/zrz+vQn876VD2bz3MF9+5CNuLf2Y7QeOhro1EWmA5qFLk2Kio7hyVD5fGt6dx6aX88SHm3hz+S7yU2H6wZUMz0tnWG4GvbKSidJcdpGQUqCLT1LiY7jz/EKuGt2TZ2ZvZvryzfx9wVamzt4MQGpCDEN7eMJ9eG46w/Iy6J6egPc8+SLSBhTo4pceGYn89KKBjEvazYQzz6L80yqWba1k6bYDLNtWyZOzNlJd63kDNTslnmG56QzLTWd4bgbDctPJStFpfkVaiwJdAhYTHUVh1zQKu6bx1TPyADhWXcuaXYdYtu0AS7Z6Qr5sbQUnJ8n0yEhkRH4GQxNqKQ5d6yJhSYEuQZUQG82IvAxG5GXw9bGe56qO17B8WyXLvEfxczfs5fXDJ/hw31xuO3cART07hbZpkTChQJdWlxIfw1jv1ZXAcxR/97Mf8O62Q3zlsdkUD+jMbef2Z5hO6yvSIs1OWzSzp8yswsxWNLL8ajNbZmbLzWy2mQ0PfpsSThJiozm/IJaZPyzhRxcUsmTrASb/8SNu+OtCVu88GOr2RDosX+ahTwUuaGL5JmCic24ocA/w5yD0JREgKS6Gm4r78OEPS7jt3P7M3biXCx/6kFueXcz63YdC3Z5Ih9NsoDvnZgL7mlg+2zm33/twLpAbpN4kQqQmxPK9Sf2Y9cOz+U5JX6avreC8B2fy/dKP2bTncKjbE+kwzJdzdJhZATDNOTekmfXuAAqdc9c3snwKMAUgJyenqLS01N9+AaiqqiIlJSWgWtW3jx6aqj90wvHGpmre/6SaGgfju8cwuU8snZOifKpv6f5Vr/rWrm+JkpKSRc65kQ0udM41ewMKgBXNrFMCrAayfNlmUVGRC1RZWVnAtapvHz34Ur/74FF396srXb+fveH6/OR195OXl7nt+4+02f5Vr/rWqm8JYKFrJFeDMsvFzIYBTwAXOuf2BmObIl1SE7jrS4OYclZvHikrp3TBFl5cuI2rRuczKlFnfxT5vBafnMvM8oGXgWucc+ta3pLIZ3VNT+CeLw+h7I5iLjmtB3+b+wn3zD3KRl1dSeQzfJm2+DwwBxhgZtvM7FtmdqOZ3ehd5S4gC3jUzJaY2cJW7FciWG6nJH5z2TCevX40VSccX37kI2as+zTUbYm0G80OuTjnrmxm+fVAg2+CirSGMb2zuGtsIk+ui+G6p+fz04sG8q0JvXQiMIl4Oh+6dEidk6J4+eZxnD+4K796fTW3v7CUY9W6XJ5ENgW6dFhJcTE8ctXp3HZuf15evJ0r/jyX3QePhbotkZBRoEuHFhVlfG9SP/50TRHluw/xpT/M4uMt+5svFAlDCnQJC+cP7srLN48nPjaKK/48l5cWbQt1SyJtToEuYWNA11RevWUCI3t24vYXlvKraauoqa0LdVsibUaBLmGlU3Icz3xzFNeOK+CJWZu4buoCKo9Uh7otkTahQJewExsdxS8nD+bXlw5l7sa9fPnRjyiv0NkbJfwp0CVsfW1UPs/fMIZDx6q55JHZfLBmd6hbEmlVCnQJayMLMnnlOxPomZ3Et55ZyKPTy0+eTE4k7OgSdBL2emQk8sK3x/HDl5bx27fWsmbnISak681SCT8KdIkIiXHRPPy1EQzslsp9b6/lVQd/XFHGmf2yObNfZ8b2ySI9MTbUbYq0iAJdIoaZcXNxX744tDt/ef0jdpHKK0t28Oy8LURHGSPyMk4F/PDcdGKiNSIpHYsCXSJOflYSk/JjKS4eSXVtHUu2HuDDdZ8yY/0eHnp/PQ++t57UhBjG98nmzP7ZnNWvM3mZSaFuW6RZCnSJaLHRUZxRkMkZBZncdt4ADhw5wUfle/lw/ad8uH4Pb63cBUBBVhJn9uvMmf2yGdsnK8RdizRMgS5ST0ZSHF8Y1o0vDOuGc46New7z4TpPuL+0eBt/m/sJUQZJMZC9oIz0xFjSvLf0Jm5pCZ6vqQkxREXpNL/SOhToIo0wM/p0TqFP5xSuHd+LEzV1LN6yn3kb97F03UZSOmVQebSayqPVbN9/9NT9mrrGp0WaQWZSHF8qgOI2+04kUijQRXwUFxPFmN5ZjOmdxfSY7RQXn/Yf6zjnOFpdeyrcK49U//v+0WoOHq1m/uZ9TF25j6S31nDn+QN0YQ4JmmYD3cyeAr4IVDjnhjSw3ICHgIuAI8C1zrnFwW5UpCMwM5LiYkiKi6FbemKD69TU1nH9Y+/y6PQN7DhwlN9eNpy4GM2okZbz5VU0FbigieUXAv28tynAYy1vSyR8xURH8Y3Bcdx5/gD+tWQH33hqPpVHdQIxablmA905NxPY18QqFwN/dR5zgQwz6xasBkXCkZlxS0lf7v/qcBZs3sflj89mx4GjoW5LOjjz5bwWZlYATGtkyGUa8Gvn3Czv4/eBHznnFjaw7hQ8R/Hk5OQUlZaWBtR0VVUVKSkpAdWqvn30oPp/16/aW8sfPj5GfLRxW1E8+WnRbbp/1bd9fUuUlJQscs6NbHChc67ZG1AArGhk2TRgQr3H7wMjm9tmUVGRC1RZWVnAtapvHz2o/rP1q3dWutH3vucG3/WWm7muos33r/q2rW8JYKFrJFeD8U7MdiCv3uNc73Mi4qPCrmn885Zx5HZK5LqnF/DCwq2hbkk6oGAE+qvA181jDFDpnNsZhO2KRJRu6Yn848axjO6dyZ0vLuOh99brVL/iF1+mLT6P5zMQ2Wa2DfgFEAvgnHsceAPPlMVyPNMWr2utZkXCXVpCLE9fO4ofv7yMB95bx44DR/nVJUOI1YnCxAfNBrpz7spmljvglqB1JBLh4mKi+P3lw+mRkcgfPihn18FjPHL16aTE63OA0jT92hdph8yM288bwP9eOpRZ5Xu44k9zqDh4LNRtSTunQBdpx64clc8TXx/Jpj2HueTR2azfrYtdS+MU6CLtXElhF/4+ZSzHa+r4ymOzmbtxb6hbknZKgS7SAQzNTeefN4+jc2o8X39yPk8sP86by3dy6JhOGSD/pndZRDqIvMwkXrppHP8zbRVvLdvOrGcXExttnFGQydmFXTi7sAu9O4fm04vSPijQRTqQjKQ47v/qCL6QvZ+UgmF8sLaCD1ZX8KvXV/Or11dTkJVESWEXJhXmMKpXps7iGGEU6CIdUHSUMbp3FqN7Z/GTCweydd8RytZW8MGaCp6dt4WnP9pMclw0E/plc3ZhF0oGdKFLWkKo25ZWpkAXCQN5mUl8fWwBXx9bwJETNcwu38sHaysoW1PB2yt3AzC0Rzol3qGZpq6qJB2XAl0kzCTFxXDOoBzOGZSDc441uw7xwRrP0fsfP1jPw++vJyYKBq6cxeDuaQzqnsagbmkUdkvTh5c6OP3viYQxM2NgtzQGdkvjlpK+7D98gg/L9/DGnOUcionhrZW7KF2w1bsuFGQlM6jbv0N+cPc0OqfG6zJ5HYQCXSSCdEqOY/Lw7qTtX0dx8Ricc+w6eIyV2w+yaudBVu04yPLtlby+/N/n18tOiWOgN+QHd09nULc06nTSsHZJgS4SwcyMbumJdEtP5JxBOaeeP3ismtU7/h3yK3cc5KlZm6iu9QR5bBQUrphFYddUCrulMbBrKgO6ppKVEh+qb0VQoItIA9ISYk/NojnpRE0d5RVVrNxRyXsLV3E4JpaytRW8sGjbqXU6p8ZT2DWVgd3SGJCTSmG3VPp2SSE+pvmrMEnLKdBFxCdxMVGesfXuaXSu2kBx8WgAPj10nLW7DrFm10FW7/R8nTp7Mydq6gDPFMs+nZMZ0DXNG/apVNdoyKY1KNBFpEU6p8bTOTWeCf2yTz1XU1vH5r2HTwX8mp2HWPzJfl5bugOAxBj46uEVXD2mJ/1zUkPVethRoItI0MVER9G3Syp9u6TypeHdTz1febSa5dsqeeSNhTw/fyvPzPmEUQWZXD0mnwuGdNXQTAsp0EWkzaQnxjKhXzY1wxMYOnIsLy7axnPzt3Br6RIyk+O4fGQuV43Kp2dWcqhb7ZAU6CISElkp8Xx7Yh9uOLM3s8r38Oy8T3jiw038acZGzuyXzX+N6cmkwi7E6PJ7PvMp0M3sAuAhIBp4wjn3688tzweeATK86/zYOfdGkHsVkTAUFWWc1b8zZ/XvzK7KY/x9wVaen7+Fb/9tEV3TErjijDyuHJVP13Sdi6Y5vlwkOhp4BDgX2AYsMLNXnXOr6q3238A/nHOPmdkgPBeOLmiFfkUkjHVNT+DWc/pxS0mfUycae/iD9fyxrJxJhV24ekxPzuyb3fyGIpQvR+ijgHLn3EYAMysFLgbqB7oD0rz304EdwWxSRCJLTHQU5w3uynmDu7Jl7xGem7+FFxZu5Z1Vu8nPTKK4aw3ja+uI1XDMZ5hr5iO8ZnYZcIFz7nrv42uA0c6579RbpxvwDtAJSAbOcc4tamBbU4ApADk5OUWlpaUBNV1VVUVKSuAn8o/0+vbQg+pV7299dZ1j0e5a3t1czYbKOnKSjEv6xTGqazRRfp5rJtTff0uUlJQscs6NbHChc67JG3AZnnHzk4+vAf74uXVuA2733h+L5+g9qqntFhUVuUCVlZUFXKv69tGD6lUfqLq6OvfA3991590/w/X80TR30UMz3fS1Fa6urq5N9h+M+pYAFrpGctWXv1e2A3n1Hud6n6vvW8A/vL8g5gAJgAa6RCTozIwRXWJ449YzeeCK4VQereYbT83nyr/MZfGW/aFuL6R8CfQFQD8z62VmccDXgFc/t84WYBKAmQ3EE+ifBrNREZH6oqOMS07L5YPbi7l78mDKK6q49NHZTPnrQtbvPhTq9kKi2UB3ztUA3wHeBlbjmc2y0sz+x8wme1e7HbjBzJYCzwPXev80EBFpVXExUXxjXAEz7izh9nP7M3vDXs5/cCZ3vLCUbfuPhLq9NuXTPHTnmVP+xueeu6ve/VXA+OC2JiLiu+T4GL47qR9Xj+nJY9PLeWbOJ7y6ZAf/NaYnt5T0iYhT+2rOj4iElczkOH72hUFMv6OYS07rwdTZm5h433Qeem89VcdrQt1eq1Kgi0hY6rArF/UAAAk2SURBVJ6RyG8uG8Y7PziLCX2zeeC9dUz8bRlPf7SJfcfqqAvDC2XrXC4iEtb6dknl8WuKWLL1AL95cw13v+b5TOSPP3yL3MxE8jOTTt1yO3nvZyV1yAtmd7yORUQCMCIvg+duGM3HWw/wr+kLSeycy9Z9R9iy7wiLPtnPoWOfHY7JTI4j71TYe4I/r1MSeZlJ7faaqgp0EYkYZsbp+Z04mB9LcfHAzyyrPFLNFm/Ab9l3hK37j7B13xGWbTvAm8t3UlNviCYtDop3fcyEvtmM65tFbqektv5WGqRAFxEB0pNiGZqUztDc9P9YVlNbx87KY2zdd4RNew8zbd5q5mzcy6veKzAVZCUxvm82E/pmM7ZPFhlJcW3dPqBAFxFpVkx0FHmZnuGWcX2z6XF0ExMnTmR9RRWz1u/ho/I9/Ovj7Tw7bwtmMLRH+qmAL+rZiYTYtrkSkwJdRCQAZkb/nFT656TyzQm9qK6tY+nWA8wq38Ps8r38ZeZGHpu+gfiYKEYWdDoV8IO7pxMd5d/JxHylQBcRCYLY6ChGFmQysiCT758Dh4/XMH/TPmaVe47gf/vWWn7LWtITY/lOSV9uOKt30HtQoIuItILk+BhKCrtQUtgFgE8PHWf2Bk+457TS1ZcU6CIibaBzajwXj+jBxSN6tNo+9ElREZEwoUAXEQkTCnQRkTChQBcRCRMKdBGRMKFAFxEJEwp0EZEwoUAXEQkTFqprOZvZp8AnAZZnA3tasPtIr28PPahe9ZFc3xI9nXOdG1zinOtwN2Ch6vVvqHrVd9T61rppyEVEJEwo0EVEwkRHDfQ/q77FQt2D6lUfyfWtImRvioqISHB11CN0ERH5HAW6iEiY6FCBbmZPmVmFma0IsD7PzMrMbJWZrTSzW/2sTzCz+Wa21Ft/d4B9RJvZx2Y2LYDazWa23MyWmNnCAOozzOxFM1tjZqvNbKwftQO8+z15O2hm3/dz/z/w/tutMLPnzcyvS7eY2a3e2pW+7Luh14yZZZrZu2a23vu1k5/1l3v3X2dmIwPY/33ef/9lZvZPM8vws/4eb+0SM3vHzLr7U19v2e1m5sws28/9/9LMttd7HVzk7/7N7Lvef4OVZvZbP/f/93r73mxmSxqrb2IbI8xs7smfIzMb5Wf9cDOb4/1ZfM3M0prqoc2Eet6kn3M/zwJOB1YEWN8NON17PxVYBwzyo96AFO/9WGAeMCaAPm4DngOmBVC7Gchuwb/hM8D13vtxQEaA24kGduH5kIOvNT2ATUCi9/E/gGv9qB8CrACS8Fxt6z2gr7+vGeC3wI+9938M/MbP+oHAAGA6MDKA/Z8HxHjv/yaA/afVu/894HF/6r3P5wFv4/lwX6Ovp0b2/0vgDh//zxqqL/H+38V7H3fxt/96y38P3BVAD+8AF3rvXwRM97N+ATDRe/+bwD2+vo5b89ahjtCdczOBfS2o3+mcW+y9fwhYjSdkfK13zrkq78NY782vd5XNLBf4AvCEP3XBYGbpeF6cTwI450445w4EuLlJwAbnnL+f9o0BEs0sBk8w7/CjdiAwzzl3xDlXA8wALm2qoJHXzMV4frHh/fplf+qdc6udc2t9abiR+ne8/QPMBXL9rD9Y72EyTbwGm/iZeQD4YVO1zdT7pJH6m4BfO+eOe9epCGT/ZmbAV4HnA+jBASePqtNp4nXYSH1/YKb3/rvAV5rqoa10qEAPJjMrAE7Dc5TtT12090+8CuBd55xf9cCDeH6Q6vysO8kB75jZIjOb4mdtL+BT4GnvkM8TZpYcYB9fo5kfpM9zzm0HfgdsAXYClc65d/zYxArgTDPLMrMkPEdWef704JXjnNvpvb8LyAlgG8HyTeBNf4vM7F4z2wpcDdzlZ+3FwHbn3FJ/91vPd7zDPk81NWTViP54/h/nmdkMMzsjwB7OBHY759YHUPt94D7vv+HvgJ/4Wb8Sz4EBwOUE9joMuogMdDNLAV4Cvv+5o51mOedqnXMj8BxVjTKzIX7s94tAhXNukV8Nf9YE59zpwIXALWZ2lh+1MXj+dHzMOXcacBjPkINfzCwOmAy84GddJzw/BL2A7kCymf2Xr/XOudV4hijeAd4ClgC1/vTQwDYdfv6VFSxm9jOgBnjW31rn3M+cc3ne2u/4sc8k4Kf4+Uvgcx4D+gAj8Pxi/r2f9TFAJjAGuBP4h/do219X4udBRT03AT/w/hv+AO9frX74JnCzmS3CM3x7IsA+giriAt3MYvGE+bPOuZcD3Y53qKIMuMCPsvHAZDPbDJQCZ5vZ//m53+3erxXAP4FG38xpwDZgW72/Kl7EE/D+uhBY7Jzb7WfdOcAm59ynzrlq4GVgnD8bcM496Zwrcs6dBezH8z6Iv3abWTcA79dG/+RvLWZ2LfBF4GrvL5VAPYt/f+73wfMLdan3dZgLLDazrr5uwDm323tgUwf8Bf9eg+B5Hb7sHcKcj+ev1UbfmG2Id8juUuDvfu77pG/gef2B58DEr+/BObfGOXeec64Izy+VDQH2EVQRFejeo4AngdXOufsDqO98ckaCmSUC5wJrfK13zv3EOZfrnCvAM2TxgXPO5yNUM0s2s9ST9/G8uebzjB/n3C5gq5kN8D41CVjla309gR4ZbQHGmFmS9/9iEp73MXxmZl28X/Px/EA/F0Afr+L5gcb79ZUAthEwM7sAz7DbZOfckQDq+9V7eDH+vQaXO+e6OOcKvK/DbXgmCuzyY//d6j28BD9eg17/wvPGKGbWH8+b8/6eufAcYI1zbpufdSftACZ6758N+DVsU+91GAX8N/B4gH0EV6jflfXnhidEdgLVeF6I3/KzfgKeP6+X4flzfQlwkR/1w4CPvfUraObd9Wa2VYyfs1yA3sBS720l8LMA9jsCWOj9Hv4FdPKzPhnYC6QH+H3fjSeAVgB/wzvTwY/6D/H8EloKTArkNQNkAe/j+SF+D8j0s/4S7/3jwG7gbT/ry4Gt9V6DTc1Saaj+Je+/3zLgNaBHoD8zNDNrqpH9/w1Y7t3/q0A3P+vjgP/zfg+LgbP97R+YCtzo42umoR4mAIu8r6N5QJGf9bfi+etwHfBrvJ+6D/VNH/0XEQkTETXkIiISzhToIiJhQoEuIhImFOgiImFCgS4iEiYU6CIiYUKBLiISJv4/aRHp+ItLS30AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "stb_mIUS8he2",
        "outputId": "26d3276d-2cb6-4da9-c816-dc0688f6ae28"
      },
      "source": [
        "pd.DataFrame(\n",
        "              np.round(\n",
        "                         np.corrcoef(X_new, rowvar=False),\n",
        "                         2\n",
        "                       )\n",
        "              )"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4    5    6   ...   13   14   15   16   17   18   19\n",
              "0   1.0  0.0  0.0 -0.0 -0.0 -0.0  0.0  ...  0.0 -0.0 -0.0  0.0  0.0 -0.0  0.0\n",
              "1   0.0  1.0 -0.0 -0.0  0.0 -0.0  0.0  ...  0.0 -0.0  0.0  0.0  0.0 -0.0  0.0\n",
              "2   0.0 -0.0  1.0 -0.0 -0.0  0.0 -0.0  ...  0.0 -0.0 -0.0  0.0  0.0 -0.0  0.0\n",
              "3  -0.0 -0.0 -0.0  1.0  0.0 -0.0 -0.0  ... -0.0  0.0  0.0 -0.0  0.0  0.0  0.0\n",
              "4  -0.0  0.0 -0.0  0.0  1.0  0.0 -0.0  ... -0.0  0.0 -0.0  0.0  0.0 -0.0 -0.0\n",
              "5  -0.0 -0.0  0.0 -0.0  0.0  1.0 -0.0  ...  0.0 -0.0  0.0  0.0 -0.0 -0.0  0.0\n",
              "6   0.0  0.0 -0.0 -0.0 -0.0 -0.0  1.0  ...  0.0 -0.0  0.0  0.0 -0.0 -0.0  0.0\n",
              "7  -0.0  0.0  0.0 -0.0  0.0  0.0 -0.0  ... -0.0  0.0 -0.0 -0.0 -0.0  0.0  0.0\n",
              "8  -0.0  0.0 -0.0  0.0 -0.0  0.0 -0.0  ...  0.0 -0.0  0.0 -0.0 -0.0  0.0  0.0\n",
              "9   0.0  0.0 -0.0  0.0  0.0 -0.0  0.0  ...  0.0  0.0 -0.0  0.0 -0.0 -0.0  0.0\n",
              "10 -0.0 -0.0  0.0  0.0  0.0 -0.0  0.0  ... -0.0  0.0  0.0  0.0  0.0  0.0 -0.0\n",
              "11 -0.0  0.0 -0.0  0.0 -0.0 -0.0 -0.0  ... -0.0  0.0  0.0  0.0  0.0 -0.0  0.0\n",
              "12 -0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0 -0.0 -0.0 -0.0\n",
              "13  0.0  0.0  0.0 -0.0 -0.0  0.0  0.0  ...  1.0 -0.0  0.0 -0.0  0.0 -0.0 -0.0\n",
              "14 -0.0 -0.0 -0.0  0.0  0.0 -0.0 -0.0  ... -0.0  1.0 -0.0 -0.0  0.0 -0.0 -0.0\n",
              "15 -0.0  0.0 -0.0  0.0 -0.0  0.0  0.0  ...  0.0 -0.0  1.0  0.0 -0.0 -0.0 -0.0\n",
              "16  0.0  0.0  0.0 -0.0  0.0  0.0  0.0  ... -0.0 -0.0  0.0  1.0 -0.0  0.0  0.0\n",
              "17  0.0  0.0  0.0  0.0  0.0 -0.0 -0.0  ...  0.0  0.0 -0.0 -0.0  1.0  0.0 -0.0\n",
              "18 -0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0  ... -0.0 -0.0 -0.0  0.0  0.0  1.0  0.0\n",
              "19  0.0  0.0  0.0  0.0 -0.0  0.0  0.0  ... -0.0 -0.0 -0.0  0.0 -0.0  0.0  1.0\n",
              "\n",
              "[20 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "0va1Jt_k-VDZ",
        "outputId": "001af61f-56e9-4b28-cecf-09f673999bce"
      },
      "source": [
        "# 2.1 Perform PCA to remove any noisy columns from data:\n",
        "pipe = mp(\n",
        "                      StandardScaler(),      # This is a must before PCA\n",
        "                      PCA(n_components=0.95),\n",
        "                      SMOTE()\n",
        "                    )\n",
        "\n",
        "\n",
        "# 2.1.1\n",
        "X_new= pipe.fit(X_train, y_train)\n",
        "X_new.shape   # (7000, 20)         "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-9b39b6a7fc14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 2.1.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m   \u001b[0;31m# (7000, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5ap3su_oY-D"
      },
      "source": [
        "\n",
        "X_new.shape  # (10000, 19)\n",
        "\n",
        "\n",
        "# 2.2.1\n",
        "X_train.shape         # (7000, 20)\n",
        "y_train.shape         # (7000,)\n",
        "np.sum(y_train)       # 103\n",
        "\n",
        "# 3.0 Perform data balancing:\n",
        "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)\n",
        "X_resampled.shape      # (13794, 20)\n",
        "#X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = BorderlineSMOTE().fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = SVMSMOTE().fit_resample(X_train,y_train)\n",
        "\n",
        "# 3.1 Create an instance of Gradient Boosting classifier\n",
        "clf_gbm = GradientBoostingClassifier(\n",
        "                                     learning_rate = 0.05,\n",
        "                                     n_estimators = 500\n",
        "                                     )\n",
        "\n",
        "# 3.2 Train classifier on resampled data\n",
        "clf_gbm.fit(X_resampled,y_resampled)\n",
        "# 3.3 MAke predictions\n",
        "y_pred_gbm= clf_gbm.predict(X_test)\n",
        "# 3.4 Performance measures\n",
        "recall_score(y_test,y_pred_gbm,pos_label = 1)     # 0.6590909090909091\n",
        "precision_score(y_test,y_pred_gbm,pos_label = 1)  # 0.29\n",
        "# 3.5\n",
        "f1_score(y_test,y_pred_gbm, pos_label =1)         # 0.40277777777777773\n",
        "# 3.6\n",
        "confusion_matrix(y_test,y_pred_gbm)\n",
        "\n",
        "# 4.0 Train gbm classifier on original data:\n",
        "clf1_gbm = GradientBoostingClassifier(\n",
        "                                       learning_rate = 0.05,\n",
        "                                       n_estimators = 500\n",
        "                                      )\n",
        "# 4.1\n",
        "clf1_gbm.fit(X_train,y_train)\n",
        "# 4.2\n",
        "y1_pred_gbm= clf_gbm.predict(X_test)\n",
        "# 4.3\n",
        "f1_score(y_test,y1_pred_gbm, pos_label =1)         #  0.40277777777777773\n",
        "recall_score(y_test,y1_pred_gbm,pos_label = 1)     #  0.6590909090909091\n",
        "precision_score(y_test,y1_pred_gbm,pos_label = 1)  # 0.29\n",
        "confusion_matrix(y_test,y1_pred_gbm)\n",
        "\n",
        "\n",
        "# 5.0 Using RandomForestClassifier on resampled data:\n",
        "clf_rf = RandomForestClassifier(n_estimators = 300)\n",
        "clf_rf.fit(X_resampled,y_resampled)\n",
        "y_pred_rf=clf_rf.predict(X_test)\n",
        "f1_score(y_test,y_pred_rf, pos_label =1)  # 0.5977011494252873\n",
        "recall_score(y_test,y_pred_rf,pos_label = 1)  # 0.5909090909090909\n",
        "precision_score(y_test,y_pred_rf,pos_label = 1) # 0.6046511627906976\n",
        "confusion_matrix(y_test,y_pred_rf)\n",
        "\n",
        "# 5.1 Using RF classifier on original data\n",
        "clf1_rf = RandomForestClassifier(n_estimators =300)\n",
        "clf1_rf.fit(X_train,y_train)\n",
        "y1_pred_rf=clf1_rf.predict(X_test)\n",
        "f1_score(y_test,y1_pred_rf, pos_label =1)       # 0.5846153846153846\n",
        "recall_score(y_test,y1_pred_rf,pos_label = 1)   # 0.4318181818181818\n",
        "precision_score(y_test,y1_pred_rf,pos_label = 1) # 0.9047619047619048\n",
        "confusion_matrix(y_test,y1_pred_rf)\n",
        "\n",
        "# 6.1 Plot confusion matrix in each case\n",
        "plot_confusion_matrix(clf_rf, X_test,y_test)\n",
        "plot_confusion_matrix(clf_gbm, X_test,y_test)\n",
        "\n",
        "\n",
        "# 6.2 Plot both ROC curves on the same axes\n",
        "#       Positive label is always 1 in these plots\n",
        "fig = plt.figure()\n",
        "ax = fig.subplots()\n",
        "plot_roc_curve(\n",
        "                 clf_gbm,            # Estimator instance\n",
        "                 X_test, y_test,\n",
        "                 response_method = 'auto',  # Default target response: predict_proba\n",
        "                 ax =ax\n",
        "               )\n",
        "\n",
        "plot_roc_curve(\n",
        "                clf_rf,\n",
        "                X_test, y_test,\n",
        "                ax =ax\n",
        "               )\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 6.3 Plot precision recall curves\n",
        "#       Positive label is always 1 in these plots\n",
        "fig = plt.figure()\n",
        "ax = fig.subplots()\n",
        "plot_precision_recall_curve(clf_rf,  X_test, y_test, ax =ax)\n",
        "plot_precision_recall_curve(clf_gbm, X_test, y_test, ax =ax)\n",
        "plt.show()\n",
        "\n",
        "##### I am done ############\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}